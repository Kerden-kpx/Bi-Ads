"""
Redisç¼“å­˜ç®¡ç†å™¨
æä¾›ä¸¤çº§ç¼“å­˜ç­–ç•¥ï¼šL1å†…å­˜ç¼“å­˜ + L2 Redisç¼“å­˜
"""
import json
import hashlib
import logging
from typing import Any, Optional, Callable
from collections.abc import Mapping, Sequence
from functools import wraps
from datetime import timedelta
import redis
from cachetools import TTLCache
from .config import settings

logger = logging.getLogger(__name__)


class CacheManager:
    """ç¼“å­˜ç®¡ç†å™¨ - æ”¯æŒä¸¤çº§ç¼“å­˜"""
    
    def __init__(self):
        """åˆå§‹åŒ–ç¼“å­˜ç®¡ç†å™¨"""
        self.redis_client: Optional[redis.Redis] = None
        self.l1_cache = TTLCache(maxsize=100, ttl=300)  # L1: å†…å­˜ç¼“å­˜ï¼Œ5åˆ†é’ŸTTL
        self._connect_redis()
    
    def _connect_redis(self):
        """è¿æ¥åˆ°RedisæœåŠ¡å™¨"""
        try:
            self.redis_client = redis.Redis(
                host=settings.REDIS_HOST,
                port=settings.REDIS_PORT,
                db=settings.REDIS_DB,
                password=settings.REDIS_PASSWORD if settings.REDIS_PASSWORD else None,
                decode_responses=True,
                socket_connect_timeout=5,
                socket_timeout=5,
                retry_on_timeout=True,
                health_check_interval=30
            )
            # æµ‹è¯•è¿æ¥
            self.redis_client.ping()
            logger.info(f"âœ… Redisè¿æ¥æˆåŠŸ: {settings.REDIS_HOST}:{settings.REDIS_PORT}")
        except Exception as e:
            logger.warning(f"âš ï¸ Redisè¿æ¥å¤±è´¥ï¼Œå°†ä»…ä½¿ç”¨å†…å­˜ç¼“å­˜: {str(e)}")
            self.redis_client = None
    
    def _generate_cache_key(self, prefix: str, *args, **kwargs) -> str:
        """
        ç”Ÿæˆç¼“å­˜é”®
        
        Args:
            prefix: é”®å‰ç¼€ï¼ˆå¦‚ 'facebook:ads'ï¼‰
            *args, **kwargs: ç”¨äºç”Ÿæˆé”®çš„å‚æ•°
            
        Returns:
            ç¼“å­˜é”®å­—ç¬¦ä¸²
        """
        def normalize(value: Any) -> str:
            """å°†å‚æ•°è½¬æ¢ä¸ºç¨³å®šçš„å­—ç¬¦ä¸²è¡¨ç¤ºï¼Œé¿å…åŒ…å«å†…å­˜åœ°å€ã€‚"""
            if value is None or isinstance(value, (str, int, float, bool)):
                return repr(value)
            if isinstance(value, Mapping):
                items = [
                    f"{normalize(k)}:{normalize(v)}"
                    for k, v in sorted(value.items(), key=lambda item: str(item[0]))
                ]
                return "{" + ",".join(items) + "}"
            if isinstance(value, set):
                items = sorted(normalize(v) for v in value)
                return "{" + ",".join(items) + "}"
            if isinstance(value, Sequence) and not isinstance(value, (str, bytes, bytearray)):
                return "[" + ",".join(normalize(v) for v in value) + "]"
            module = getattr(value.__class__, "__module__", "")
            name = getattr(value.__class__, "__name__", value.__class__.__qualname__)
            return f"<{module}.{name}>"
        
        # å°†å‚æ•°åºåˆ—åŒ–ä¸ºå­—ç¬¦ä¸²
        key_parts = [normalize(arg) for arg in args]
        key_parts.extend([f"{k}={normalize(v)}" for k, v in sorted(kwargs.items())])
        key_str = ":".join(key_parts)
        if not key_str:
            key_str = "default"
        
        # å¯¹äºé•¿é”®ï¼Œä½¿ç”¨å“ˆå¸Œ
        if len(key_str) > 100:
            key_hash = hashlib.md5(key_str.encode()).hexdigest()[:16]
            return f"{prefix}:{key_hash}"
        
        return f"{prefix}:{key_str}"
    
    def get(self, key: str) -> Optional[Any]:
        """
        è·å–ç¼“å­˜æ•°æ®ï¼ˆå…ˆL1åL2ï¼‰
        
        Args:
            key: ç¼“å­˜é”®
            
        Returns:
            ç¼“å­˜çš„æ•°æ®ï¼Œå¦‚æœä¸å­˜åœ¨è¿”å›None
        """
        # å…ˆæŸ¥L1ç¼“å­˜
        if key in self.l1_cache:
            logger.debug(f"ğŸ¯ L1ç¼“å­˜å‘½ä¸­: {key}")
            return self.l1_cache[key]
        
        # å†æŸ¥L2ç¼“å­˜ï¼ˆRedisï¼‰
        if self.redis_client:
            try:
                value = self.redis_client.get(key)
                if value:
                    logger.debug(f"ğŸ¯ L2ç¼“å­˜å‘½ä¸­: {key}")
                    # ååºåˆ—åŒ–
                    data = json.loads(value)
                    # å†™å…¥L1ç¼“å­˜
                    self.l1_cache[key] = data
                    return data
            except Exception as e:
                logger.error(f"Redisè·å–å¤±è´¥: {key}, {str(e)}")
        
        logger.debug(f"âŒ ç¼“å­˜æœªå‘½ä¸­: {key}")
        return None
    
    def set(self, key: str, value: Any, ttl: int = 3600):
        """
        è®¾ç½®ç¼“å­˜æ•°æ®ï¼ˆåŒæ—¶å†™å…¥L1å’ŒL2ï¼‰
        
        Args:
            key: ç¼“å­˜é”®
            value: è¦ç¼“å­˜çš„æ•°æ®
            ttl: è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤1å°æ—¶
        """
        # å†™å…¥L1ç¼“å­˜
        self.l1_cache[key] = value
        
        # å†™å…¥L2ç¼“å­˜ï¼ˆRedisï¼‰
        if self.redis_client:
            try:
                serialized = json.dumps(value, ensure_ascii=False)
                self.redis_client.setex(key, ttl, serialized)
                logger.debug(f"âœ… ç¼“å­˜å·²è®¾ç½®: {key} (TTL: {ttl}s)")
            except Exception as e:
                logger.error(f"Redisè®¾ç½®å¤±è´¥: {key}, {str(e)}")
    
    def delete(self, key: str):
        """åˆ é™¤ç¼“å­˜æ•°æ®"""
        # åˆ é™¤L1ç¼“å­˜
        self.l1_cache.pop(key, None)
        
        # åˆ é™¤L2ç¼“å­˜
        if self.redis_client:
            try:
                self.redis_client.delete(key)
                logger.debug(f"ğŸ—‘ï¸ ç¼“å­˜å·²åˆ é™¤: {key}")
            except Exception as e:
                logger.error(f"Redisåˆ é™¤å¤±è´¥: {key}, {str(e)}")
    
    def clear_pattern(self, pattern: str) -> int:
        """
        æ¸…é™¤åŒ¹é…æ¨¡å¼çš„æ‰€æœ‰ç¼“å­˜
        
        Args:
            pattern: åŒ¹é…æ¨¡å¼ï¼ˆå¦‚ 'facebook:*'ï¼‰
            
        Returns:
            åˆ é™¤çš„é”®æ•°é‡
        """
        deleted_count = 0
        
        # æ¸…é™¤L1ç¼“å­˜ä¸­åŒ¹é…çš„é”®
        keys_to_delete = [k for k in self.l1_cache.keys() if self._match_pattern(k, pattern)]
        for key in keys_to_delete:
            self.l1_cache.pop(key, None)
            deleted_count += 1
        
        # æ¸…é™¤L2ç¼“å­˜ä¸­åŒ¹é…çš„é”®
        if self.redis_client:
            try:
                cursor = 0
                while True:
                    cursor, keys = self.redis_client.scan(cursor, match=pattern, count=100)
                    if keys:
                        self.redis_client.delete(*keys)
                        deleted_count += len(keys)
                    if cursor == 0:
                        break
                logger.info(f"ğŸ—‘ï¸ æ¸…é™¤ç¼“å­˜æ¨¡å¼ '{pattern}': {deleted_count} ä¸ªé”®")
            except Exception as e:
                logger.error(f"Redisæ‰¹é‡åˆ é™¤å¤±è´¥: {pattern}, {str(e)}")
        
        return deleted_count
    
    def _match_pattern(self, key: str, pattern: str) -> bool:
        """ç®€å•çš„æ¨¡å¼åŒ¹é…ï¼ˆæ”¯æŒ*é€šé…ç¬¦ï¼‰"""
        import re
        regex_pattern = pattern.replace('*', '.*')
        return re.match(f'^{regex_pattern}$', key) is not None
    
    def get_stats(self) -> dict:
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        stats = {
            "l1_cache": {
                "size": len(self.l1_cache),
                "maxsize": self.l1_cache.maxsize,
                "ttl": self.l1_cache.ttl
            },
            "redis": {
                "connected": self.redis_client is not None
            }
        }
        
        if self.redis_client:
            try:
                info = self.redis_client.info()
                stats["redis"].update({
                    "used_memory_human": info.get("used_memory_human", "N/A"),
                    "connected_clients": info.get("connected_clients", 0),
                    "total_commands_processed": info.get("total_commands_processed", 0),
                    "keyspace_hits": info.get("keyspace_hits", 0),
                    "keyspace_misses": info.get("keyspace_misses", 0)
                })
                
                # è®¡ç®—å‘½ä¸­ç‡
                hits = info.get("keyspace_hits", 0)
                misses = info.get("keyspace_misses", 0)
                if hits + misses > 0:
                    stats["redis"]["hit_rate"] = f"{hits / (hits + misses) * 100:.2f}%"
            except Exception as e:
                logger.error(f"è·å–Redisç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {str(e)}")
        
        return stats
    
    def flush_all(self):
        """æ¸…ç©ºæ‰€æœ‰ç¼“å­˜ï¼ˆè°¨æ…ä½¿ç”¨ï¼‰"""
        # æ¸…ç©ºL1
        self.l1_cache.clear()
        
        # æ¸…ç©ºL2
        if self.redis_client:
            try:
                self.redis_client.flushdb()
                logger.warning("âš ï¸ å·²æ¸…ç©ºæ‰€æœ‰Redisç¼“å­˜")
            except Exception as e:
                logger.error(f"Redisæ¸…ç©ºå¤±è´¥: {str(e)}")


# å…¨å±€ç¼“å­˜ç®¡ç†å™¨å®ä¾‹
cache_manager = CacheManager()


def cached(prefix: str, ttl: int = 3600, key_builder: Optional[Callable] = None):
    """
    ç¼“å­˜è£…é¥°å™¨ - ç”¨äºç¼“å­˜å‡½æ•°è¿”å›å€¼
    
    Args:
        prefix: ç¼“å­˜é”®å‰ç¼€
        ttl: è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰
        key_builder: è‡ªå®šä¹‰é”®ç”Ÿæˆå‡½æ•°
    
    Example:
        @cached(prefix="facebook:impressions", ttl=1800)
        async def get_impressions_data(start_date, end_date):
            # è°ƒç”¨APIè·å–æ•°æ®
            return data
    """
    def decorator(func: Callable):
        @wraps(func)
        async def async_wrapper(*args, **kwargs):
            # ç”Ÿæˆç¼“å­˜é”®
            if key_builder:
                cache_key = key_builder(*args, **kwargs)
            else:
                cache_key = cache_manager._generate_cache_key(prefix, *args, **kwargs)
            
            # å°è¯•ä»ç¼“å­˜è·å–
            cached_data = cache_manager.get(cache_key)
            if cached_data is not None:
                return cached_data
            
            # ç¼“å­˜æœªå‘½ä¸­ï¼Œæ‰§è¡Œå‡½æ•°
            result = await func(*args, **kwargs)
            
            # å­˜å…¥ç¼“å­˜
            if result is not None:
                cache_manager.set(cache_key, result, ttl)
            
            return result
        
        @wraps(func)
        def sync_wrapper(*args, **kwargs):
            # ç”Ÿæˆç¼“å­˜é”®
            if key_builder:
                cache_key = key_builder(*args, **kwargs)
            else:
                cache_key = cache_manager._generate_cache_key(prefix, *args, **kwargs)
            
            # å°è¯•ä»ç¼“å­˜è·å–
            cached_data = cache_manager.get(cache_key)
            if cached_data is not None:
                return cached_data
            
            # ç¼“å­˜æœªå‘½ä¸­ï¼Œæ‰§è¡Œå‡½æ•°
            result = func(*args, **kwargs)
            
            # å­˜å…¥ç¼“å­˜
            if result is not None:
                cache_manager.set(cache_key, result, ttl)
            
            return result
        
        # æ ¹æ®å‡½æ•°ç±»å‹è¿”å›å¯¹åº”çš„wrapper
        import inspect
        if inspect.iscoroutinefunction(func):
            return async_wrapper
        else:
            return sync_wrapper
    
    return decorator


def invalidate_cache(pattern: str):
    """
    æ¸…é™¤ç¼“å­˜çš„è¾…åŠ©å‡½æ•°
    
    Args:
        pattern: ç¼“å­˜é”®æ¨¡å¼ï¼ˆæ”¯æŒ*é€šé…ç¬¦ï¼‰
    
    Example:
        invalidate_cache("facebook:*")  # æ¸…é™¤æ‰€æœ‰Facebookç¼“å­˜
    """
    return cache_manager.clear_pattern(pattern)

