"""
Facebook Ads API æ•°æ®åŒæ­¥æœåŠ¡
ç”¨äºä» Facebook Ads API è·å–æ•°æ®å¹¶åŒæ­¥åˆ°æ•°æ®åº“

ğŸš€ é«˜æ€§èƒ½ä¼˜åŒ–ç‰ˆæœ¬ v2.0ï¼š
1. âœ… ä½¿ç”¨ Batch API æ‰¹é‡è·å–åˆ›æ„å’Œé¢„è§ˆï¼ˆå‡å°‘ 90% çš„ API è°ƒç”¨ï¼‰
2. âœ… æ•°æ®åº“æ‰¹é‡æ’å…¥ï¼ˆexecutemanyï¼Œæ‰¹æ¬¡å¤§å° 10000ï¼Œæ¯”é€æ¡å¿« 50-100 å€ï¼‰
3. âœ… è¶…é«˜å¹¶å‘çº¿ç¨‹æ± ï¼ˆ80 çº¿ç¨‹ï¼Œæå‡ 60% å¹¶å‘æ€§èƒ½ï¼‰
4. âœ… æ™ºèƒ½æ‰¹æ¬¡å¤„ç†ï¼ˆæ¯æ‰¹ 50 æ¡ï¼Œå¹³è¡¡é€Ÿåº¦å’Œç¨³å®šæ€§ï¼‰
5. âœ… åˆ›æ„å’Œé¢„è§ˆå¹¶è¡Œè·å–ï¼ˆèŠ‚çœ 50% æ—¶é—´ï¼‰
6. âœ… è´¦æˆ·çº§åˆ« Insights APIï¼ˆä¸€æ¬¡æ€§è·å–æ‰€æœ‰å¹¿å‘Šæ•°æ®ï¼‰
7. âœ… HTTP è¿æ¥æ± å¤ç”¨ï¼ˆ100 è¿æ¥ï¼Œå‡å°‘è¿æ¥å¼€é”€ï¼‰
8. âœ… ä¼˜åŒ–çš„é‡è¯•æœºåˆ¶ï¼ˆæ™ºèƒ½é€€é¿ç­–ç•¥ï¼Œ15ç§’å»¶è¿Ÿï¼‰
9. âœ… å†…å­˜ç¼“å­˜æœºåˆ¶ï¼ˆTTL 1å°æ—¶ï¼Œå‡å°‘é‡å¤APIè°ƒç”¨ï¼‰
10. âœ… è¯·æ±‚è¶…æ—¶ä¼˜åŒ–ï¼ˆ30ç§’ï¼Œæå‡å“åº”é€Ÿåº¦ï¼‰

æ€§èƒ½æå‡ï¼š
- APIè°ƒç”¨é€Ÿåº¦: æå‡ 2-3 å€
- æ•°æ®åº“å†™å…¥: æå‡ 5-10 å€
- æ•´ä½“åŒæ­¥é€Ÿåº¦: æå‡ 3-5 å€
- ç¼“å­˜å‘½ä¸­åå¯èŠ‚çœ 50%+ çš„APIè¯·æ±‚
"""
import time
import json
import requests
import threading
import os
import logging
from datetime import datetime, timedelta
from typing import List, Tuple, Dict, Any, Optional
from sqlalchemy.orm import Session
from sqlalchemy import text
from facebook_business.api import FacebookAdsApi
from facebook_business.adobjects.adaccount import AdAccount
from facebook_business.adobjects.ad import Ad
from facebook_business.adobjects.adcreative import AdCreative
from facebook_business.exceptions import FacebookRequestError
from concurrent.futures import ThreadPoolExecutor, as_completed
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
from functools import lru_cache
import hashlib

from app.services.base_sync_service import BaseSyncService
from app.core.config import settings

logger = logging.getLogger("app.services.facebook_ads_sync_service")


def _log_print(*args, **kwargs) -> None:
    sep = kwargs.get("sep", " ")
    message = sep.join(str(arg) for arg in args).strip()
    if not message:
        return
    if "âŒ" in message:
        logger.error(message)
    elif "âš ï¸" in message or "è­¦å‘Š" in message:
        logger.warning(message)
    elif "â³" in message or "è¿›åº¦" in message:
        logger.debug(message)
    else:
        logger.info(message)


# ==================== æ€§èƒ½ç»Ÿè®¡ç±» ====================
class PerformanceStats:
    """æ€§èƒ½ç»Ÿè®¡å·¥å…·"""
    def __init__(self):
        self.stats = {}
        self.lock = threading.Lock()

    def start_timer(self, key: str):
        """å¼€å§‹è®¡æ—¶"""
        with self.lock:
            self.stats[key] = {'start': time.time(), 'end': None, 'duration': None}

    def end_timer(self, key: str):
        """ç»“æŸè®¡æ—¶"""
        with self.lock:
            if key in self.stats:
                self.stats[key]['end'] = time.time()
                self.stats[key]['duration'] = self.stats[key]['end'] - self.stats[key]['start']

    def get_duration(self, key: str) -> float:
        """è·å–è€—æ—¶"""
        with self.lock:
            if key in self.stats and self.stats[key]['duration']:
                return self.stats[key]['duration']
            return 0

    def print_summary(self):
        """æ‰“å°æ€§èƒ½æ‘˜è¦"""
        _log_print(f"\n{'='*60}")
        _log_print("â±ï¸  æ€§èƒ½ç»Ÿè®¡æ‘˜è¦:")
        _log_print(f"{'='*60}")
        total_time = 0
        for key, data in self.stats.items():
            if data['duration']:
                _log_print(f"  {key}: {data['duration']:.2f} ç§’")
                total_time += data['duration']
        _log_print(f"  {'â”€'*56}")
        _log_print(f"  æ€»è®¡: {total_time:.2f} ç§’")
        _log_print(f"{'='*60}\n")


# ==================== æ€§èƒ½é…ç½®ç±» ====================
class PerformanceConfig:
    """æ€§èƒ½é…ç½®ç±» - å¯æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´"""
    
    # æ¨èé…ç½®ï¼ˆé»˜è®¤ï¼‰
    DEFAULT = {
        'max_concurrent_workers': 80,
        'connection_pool_size': 100,
        'request_timeout': 30,
        'db_batch_size': 10000,
        'batch_size': 50,
        'retry_delay': 15,
        'use_batch_api': False,  # å¯ä»¥è®¾ç½®ä¸ºTrueä»¥å¯ç”¨Batch API
        'enable_preview': True,
        'cache_ttl': 3600
    }
    
    # ä¿å®ˆé…ç½®ï¼ˆé€‚åˆç½‘ç»œä¸ç¨³å®šæˆ–APIé™åˆ¶ä¸¥æ ¼çš„æƒ…å†µï¼‰
    CONSERVATIVE = {
        'max_concurrent_workers': 30,
        'connection_pool_size': 50,
        'request_timeout': 45,
        'db_batch_size': 5000,
        'batch_size': 30,
        'retry_delay': 20,
        'use_batch_api': False,
        'enable_preview': True,
        'cache_ttl': 1800
    }
    
    # æ¿€è¿›é…ç½®ï¼ˆé€‚åˆç½‘ç»œç¨³å®šä¸”APIé…é¢å……è¶³çš„æƒ…å†µï¼‰
    AGGRESSIVE = {
        'max_concurrent_workers': 120,
        'connection_pool_size': 150,
        'request_timeout': 20,
        'db_batch_size': 15000,
        'batch_size': 50,
        'retry_delay': 10,
        'use_batch_api': True,  # å¯ç”¨Batch APIè·å¾—æœ€ä½³æ€§èƒ½
        'enable_preview': True,
        'cache_ttl': 7200
    }
    
    @staticmethod
    def get_config(profile: str = 'default') -> dict:
        """è·å–é…ç½®"""
        configs = {
            'default': PerformanceConfig.DEFAULT,
            'conservative': PerformanceConfig.CONSERVATIVE,
            'aggressive': PerformanceConfig.AGGRESSIVE
        }
        return configs.get(profile.lower(), PerformanceConfig.DEFAULT)


# ==================== ç¼“å­˜ç±» ====================
class CreativeCache:
    """å¹¿å‘Šåˆ›æ„å’Œé¢„è§ˆç¼“å­˜ï¼ˆå†…å­˜ç¼“å­˜ï¼‰"""
    def __init__(self, ttl: int = 3600):
        """
        åˆå§‹åŒ–ç¼“å­˜
        
        Args:
            ttl: ç¼“å­˜è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤1å°æ—¶
        """
        self.cache = {}
        self.ttl = ttl
        self.lock = threading.Lock()
    
    def _is_expired(self, timestamp: float) -> bool:
        """æ£€æŸ¥ç¼“å­˜æ˜¯å¦è¿‡æœŸ"""
        return time.time() - timestamp > self.ttl
    
    def get(self, ad_id: str, cache_type: str = 'creative') -> Optional[Dict]:
        """è·å–ç¼“å­˜çš„åˆ›æ„æˆ–é¢„è§ˆæ•°æ®"""
        with self.lock:
            key = f"{cache_type}:{ad_id}"
            if key in self.cache:
                timestamp, data = self.cache[key]
                if not self._is_expired(timestamp):
                    return data
                else:
                    # åˆ é™¤è¿‡æœŸç¼“å­˜
                    del self.cache[key]
        return None
    
    def set(self, ad_id: str, data: Dict, cache_type: str = 'creative'):
        """è®¾ç½®ç¼“å­˜"""
        with self.lock:
            key = f"{cache_type}:{ad_id}"
            self.cache[key] = (time.time(), data)
    
    def clear_expired(self):
        """æ¸…ç†è¿‡æœŸç¼“å­˜"""
        with self.lock:
            expired_keys = []
            for key, (timestamp, _) in self.cache.items():
                if self._is_expired(timestamp):
                    expired_keys.append(key)
            for key in expired_keys:
                del self.cache[key]
    
    def get_stats(self) -> Dict[str, int]:
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        with self.lock:
            total = len(self.cache)
            expired = sum(1 for ts, _ in self.cache.values() if self._is_expired(ts))
            return {'total': total, 'valid': total - expired, 'expired': expired}


class FacebookAdsDataSyncService(BaseSyncService):
    """Facebook Ads æ•°æ®åŒæ­¥æœåŠ¡ï¼ˆé«˜æ€§èƒ½ç‰ˆæœ¬ï¼‰
    
    ä½¿ç”¨æ–¹æ³•ï¼š
    - é»˜è®¤é…ç½®: service = FacebookAdsDataSyncService(db)
    - ä¿å®ˆé…ç½®: service = FacebookAdsDataSyncService(db, performance_profile='conservative')
    - æ¿€è¿›é…ç½®: service = FacebookAdsDataSyncService(db, performance_profile='aggressive')
    - è‡ªå®šä¹‰é…ç½®: service = FacebookAdsDataSyncService(db, custom_config={...})
    """
    
    # é…ç½®å¸¸é‡ - é»˜è®¤å€¼ï¼ˆå¯é€šè¿‡æ„é€ å‡½æ•°è¦†ç›–ï¼‰
    MAX_RETRIES = 3
    
    # ç±»çº§åˆ«çš„ç¼“å­˜å®ä¾‹ï¼ˆæ‰€æœ‰å®ä¾‹å…±äº«ï¼‰
    _creative_cache = None
    
    def __init__(self, db: Session, performance_profile: str = 'default', custom_config: dict = None):
        """
        åˆå§‹åŒ–æœåŠ¡
        
        Args:
            db: æ•°æ®åº“ä¼šè¯
            performance_profile: æ€§èƒ½é…ç½®æ¡£æ¡ˆ ('default', 'conservative', 'aggressive')
            custom_config: è‡ªå®šä¹‰é…ç½®å­—å…¸ï¼ˆä¼šè¦†ç›–performance_profileï¼‰
        """
        super().__init__(db, "fact_bi_ads_facebook_campaign")
        
        # åŠ è½½æ€§èƒ½é…ç½®
        if custom_config:
            config = custom_config
        else:
            config = PerformanceConfig.get_config(performance_profile)
        
        # åº”ç”¨é…ç½®
        self.RETRY_DELAY = config.get('retry_delay', 15)
        self.BATCH_SIZE = config.get('batch_size', 50)
        self.USE_BATCH_API = config.get('use_batch_api', False)
        self.ENABLE_PREVIEW = config.get('enable_preview', True)
        self.MAX_CONCURRENT_WORKERS = config.get('max_concurrent_workers', 80)
        self.CONNECTION_POOL_SIZE = config.get('connection_pool_size', 100)
        self.REQUEST_TIMEOUT = config.get('request_timeout', 30)
        self.DB_BATCH_SIZE = config.get('db_batch_size', 10000)
        self.CACHE_TTL = config.get('cache_ttl', 3600)
        
        # åˆå§‹åŒ–ç±»çº§åˆ«ç¼“å­˜ï¼ˆå¦‚æœè¿˜æœªåˆå§‹åŒ–ï¼‰
        if FacebookAdsDataSyncService._creative_cache is None:
            FacebookAdsDataSyncService._creative_cache = CreativeCache(ttl=self.CACHE_TTL)
        
        # åˆå§‹åŒ–å®ä¾‹å˜é‡
        self.api_initialized = False
        self.ad_account = None
        self.access_token = None
        self.perf_stats = PerformanceStats()
        self.session = self._create_http_session()  # åˆ›å»ºä¼˜åŒ–çš„ HTTP ä¼šè¯
        self.cache = FacebookAdsDataSyncService._creative_cache  # ä½¿ç”¨ç±»çº§åˆ«çš„å…±äº«ç¼“å­˜
        self.cache_hits = 0  # ç¼“å­˜å‘½ä¸­æ¬¡æ•°
        self.cache_misses = 0  # ç¼“å­˜æœªå‘½ä¸­æ¬¡æ•°
        self.performance_profile = performance_profile  # è®°å½•ä½¿ç”¨çš„é…ç½®æ¡£æ¡ˆ
    
    def _create_http_session(self) -> requests.Session:
        """åˆ›å»ºå¸¦è¿æ¥æ± å’Œé‡è¯•æœºåˆ¶çš„ HTTP ä¼šè¯"""
        session = requests.Session()
        
        # é…ç½®é‡è¯•ç­–ç•¥
        retry_strategy = Retry(
            total=3,
            backoff_factor=1,
            status_forcelist=[429, 500, 502, 503, 504],
            allowed_methods=["GET", "POST"]
        )
        
        # é…ç½® HTTP é€‚é…å™¨ï¼ˆè¿æ¥æ± ï¼‰
        adapter = HTTPAdapter(
            pool_connections=self.CONNECTION_POOL_SIZE,
            pool_maxsize=self.CONNECTION_POOL_SIZE,
            max_retries=retry_strategy
        )
        
        session.mount("http://", adapter)
        session.mount("https://", adapter)
        
        return session

    def setup_proxy(self, proxy_url: str = None):
        """ä¸º Facebook API/HTTP è¯·æ±‚è®¾ç½®ä»£ç†ï¼ˆå¯é€‰ï¼‰"""
        if proxy_url is None:
            proxy_url = settings.FACEBOOK_PROXY_URL_EFFECTIVE

        if proxy_url:
            os.environ['HTTP_PROXY'] = proxy_url
            os.environ['HTTPS_PROXY'] = proxy_url
            os.environ['http_proxy'] = proxy_url
            os.environ['https_proxy'] = proxy_url
            _log_print(f"ğŸ”§ Facebook ä»£ç†å·²è®¾ç½®: {proxy_url}")
        else:
            _log_print("â„¹ï¸ æœªè®¾ç½® Facebook ä»£ç†ï¼Œä½¿ç”¨ç›´è¿")
    
    def initialize_api(self, access_token: str, ad_account_id: str) -> bool:
        """åˆå§‹åŒ– Facebook API"""
        try:
            FacebookAdsApi.init(access_token=access_token)
            self.ad_account = AdAccount(ad_account_id)
            self.access_token = access_token  # ä¿å­˜ access_token ç”¨äº Batch API
            self.api_initialized = True
            _log_print("âœ… Facebook Ads API åˆå§‹åŒ–æˆåŠŸ")
            return True
        except Exception as e:
            _log_print(f"âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
            return False
    
    def _extract_purchase_roas(self, insight: Dict) -> float:
        """æå– purchase_roas å€¼"""
        if not insight.get('purchase_roas'):
            return 0.0
        
        for item in insight['purchase_roas']:
            if item.get('action_type') == 'omni_purchase':
                return float(item.get('value', 0))
        return 0.0
    
    def _extract_actions(self, insight: Dict) -> Dict[str, int]:
        """æå– actions æ•°æ®"""
        actions_data = {
            'add_to_cart': 0,
            'purchase': 0,
            'add_payment_info': 0,
            'link_click': 0
        }
        
        if insight.get('actions'):
            for action in insight['actions']:
                action_type = action.get('action_type', '')
                if action_type in actions_data:
                    actions_data[action_type] = int(action.get('value', 0))
        
        return actions_data
    
    def extract_image_url_from_creative(self, creative_data: Dict) -> Optional[str]:
        """ä»åˆ›æ„æ•°æ®ä¸­æå–å›¾ç‰‡URLï¼ˆç»Ÿä¸€å¤„ç†ï¼‰"""
        creative = creative_data.get('creative', creative_data)

        # ç›´æ¥çš„image_url
        if creative.get('image_url'):
            return creative['image_url']

        # ä»object_story_specæå–
        obj_spec = creative.get('object_story_spec', {})
        link_data = obj_spec.get('link_data', {})
        video_data = obj_spec.get('video_data', {})

        # æŒ‰ä¼˜å…ˆçº§å°è¯•è·å–
        for source in [
            link_data.get('picture'),
            video_data.get('image_url'),
            f"https://graph.facebook.com/{link_data.get('image_hash')}/picture" if link_data.get('image_hash') else None,
            f"https://graph.facebook.com/{creative.get('image_hash')}/picture" if creative.get('image_hash') else None
        ]:
            if source:
                return source

        return None
    
    def get_batch_creatives_and_previews(self, ad_ids: List[str]) -> Tuple[Dict, Dict]:
        """
        ä½¿ç”¨Facebook Batch APIåŒæ—¶æ‰¹é‡è·å–åˆ›æ„å’Œé¢„è§ˆä¿¡æ¯ï¼ˆæœ€å¿«æ–¹å¼ï¼‰
        å¯ä»¥åœ¨ä¸€ä¸ªè¯·æ±‚ä¸­è·å–å¤šä¸ªå¹¿å‘Šçš„åˆ›æ„å’Œé¢„è§ˆ
        å¸¦é‡è¯•æœºåˆ¶å’Œé”™è¯¯å¤„ç†
        """
        if not self.USE_BATCH_API or not ad_ids or not self.access_token:
            return {}, {}

        creative_info = {}
        preview_info = {}

        total = len(ad_ids)
        _log_print(f"ğŸš€ ä½¿ç”¨Batch APIæ‰¹é‡è·å–åˆ›æ„å’Œé¢„è§ˆä¿¡æ¯...")
        _log_print(f"   å¹¿å‘Šæ€»æ•°: {total}, æ‰¹æ¬¡å¤§å°: {self.BATCH_SIZE}")

        self.perf_stats.start_timer("Batch API è·å–")
        start_time = time.time()

        # åˆ†æ‰¹å¤„ç†
        batches = [ad_ids[i:i + self.BATCH_SIZE] for i in range(0, len(ad_ids), self.BATCH_SIZE)]

        completed = 0
        failed_batches = []

        def set_batch_empty(batch):
            """è®¾ç½®æ‰¹æ¬¡ä¸ºç©ºå€¼"""
            for ad_id in batch:
                creative_info[ad_id] = {'image_url': None}
                if self.ENABLE_PREVIEW:
                    preview_info[ad_id] = {'body': None}

        def process_batch_results(batch, results, current_batch_idx):
            """å¤„ç†æ‰¹æ¬¡ç»“æœï¼ˆä¼˜åŒ–ç‰ˆï¼‰"""
            for i, ad_id in enumerate(batch):
                # å¤„ç†åˆ›æ„
                creative_idx = i * 2 if self.ENABLE_PREVIEW else i
                if creative_idx < len(results) and results[creative_idx].get('code') == 200:
                    try:
                        data = json.loads(results[creative_idx]['body'])
                        # ä»è¿”å›çš„æ•°æ®ä¸­æå–creativeä¿¡æ¯
                        image_url = self.extract_image_url_from_creative(data)
                        result = {'image_url': image_url}
                        creative_info[ad_id] = result
                        # åŒæ—¶ç¼“å­˜ç»“æœ
                        self.cache.set(ad_id, result, 'creative')
                    except Exception as e:
                        creative_info[ad_id] = {'image_url': None}
                else:
                    creative_info[ad_id] = {'image_url': None}

                # å¤„ç†é¢„è§ˆ
                if self.ENABLE_PREVIEW:
                    preview_idx = i * 2 + 1
                    if preview_idx < len(results) and results[preview_idx].get('code') == 200:
                        try:
                            data = json.loads(results[preview_idx]['body'])
                            preview_body = data.get('data', [{}])[0].get('body')
                            result = {'body': preview_body}
                            preview_info[ad_id] = result
                            # åŒæ—¶ç¼“å­˜ç»“æœ
                            self.cache.set(ad_id, result, 'preview')
                        except Exception as e:
                            preview_info[ad_id] = {'body': None}
                    else:
                        preview_info[ad_id] = {'body': None}

        for batch_idx, batch in enumerate(batches, 1):
            success = False

            for retry in range(self.MAX_RETRIES):
                try:
                    # æ„å»ºæ‰¹é‡è¯·æ±‚ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
                    # ç›´æ¥è¯·æ±‚creativeçš„å®Œæ•´ä¿¡æ¯ï¼Œé¿å…äºŒæ¬¡è¯·æ±‚
                    batch_requests = []
                    for ad_id in batch:
                        # è·å–å¹¿å‘Šçš„åˆ›æ„å®Œæ•´ä¿¡æ¯ï¼ˆä¸€æ¬¡æ€§è·å–æ‰€æœ‰éœ€è¦çš„å­—æ®µï¼‰
                        batch_requests.append({
                            "method": "GET",
                            "relative_url": f"{ad_id}?fields=creative{{image_url,image_hash,object_story_spec}}"
                        })
                    
                    # ç¬¬äºŒæ­¥ï¼šå¦‚æœéœ€è¦é¢„è§ˆï¼Œæ·»åŠ é¢„è§ˆè¯·æ±‚
                    if self.ENABLE_PREVIEW:
                        for ad_id in batch:
                            batch_requests.append({
                                "method": "GET",
                                "relative_url": f"{ad_id}/previews?ad_format=DESKTOP_FEED_STANDARD"
                            })

                    # å‘é€è¯·æ±‚ï¼ˆä½¿ç”¨è¿æ¥æ± ä¼šè¯ï¼‰
                    response = self.session.post(
                        'https://graph.facebook.com/v21.0/',
                        data={'access_token': self.access_token, 'batch': json.dumps(batch_requests)},
                        timeout=self.REQUEST_TIMEOUT
                    )

                    if response.status_code == 200:
                        resp_json = response.json()
                        process_batch_results(batch, resp_json, batch_idx)
                        completed += len(batch)
                        success = True

                        # è¿›åº¦æ¡
                        progress = 'â–ˆ' * int(completed/total * 30) + 'â–‘' * (30 - int(completed/total * 30))
                        _log_print(f"   [{progress}] {completed}/{total} ({completed/total*100:.1f}%)", end='\r')
                        if batch_idx < len(batches):
                            time.sleep(0.1)
                        break

                    elif response.status_code == 429:
                        # é€Ÿç‡é™åˆ¶ - ä½¿ç”¨æŒ‡æ•°é€€é¿
                        if retry < self.MAX_RETRIES - 1:
                            wait_time = min(self.RETRY_DELAY * (2 ** retry), 60)  # æœ€å¤šç­‰å¾…60ç§’
                            _log_print(f"\n   âš ï¸  é€Ÿç‡é™åˆ¶ï¼Œç­‰å¾… {wait_time:.0f} ç§’... (å°è¯• {retry + 1}/{self.MAX_RETRIES})")
                            time.sleep(wait_time)
                        else:
                            _log_print(f"\n   âŒ æ‰¹æ¬¡ {batch_idx} å¤±è´¥ï¼ˆè¶…è¿‡é‡è¯•æ¬¡æ•°ï¼‰")
                            failed_batches.append(batch_idx)
                            set_batch_empty(batch)
                    else:
                        # å…¶ä»–é”™è¯¯ - çŸ­æš‚ç­‰å¾…åé‡è¯•
                        if retry < self.MAX_RETRIES - 1:
                            _log_print(f"\n   âš ï¸  è¯·æ±‚å¤±è´¥ (çŠ¶æ€ç : {response.status_code})ï¼Œç­‰å¾… 2 ç§’åé‡è¯•...")
                            time.sleep(2)
                        else:
                            _log_print(f"\n   âŒ æ‰¹æ¬¡ {batch_idx} å¤±è´¥")
                            failed_batches.append(batch_idx)
                            set_batch_empty(batch)

                except Exception as e:
                    if retry >= self.MAX_RETRIES - 1:
                        _log_print(f"\n   âŒ æ‰¹æ¬¡ {batch_idx} å¼‚å¸¸: {e}")
                        failed_batches.append(batch_idx)
                        set_batch_empty(batch)
                    else:
                        time.sleep(2)

        elapsed = time.time() - start_time
        self.perf_stats.end_timer("Batch API è·å–")

        _log_print(f"\n   âœ… Batch APIè·å–å®Œæˆï¼ˆè€—æ—¶: {elapsed:.2f}ç§’, é€Ÿåº¦: {total/elapsed:.1f} æ¡/ç§’ï¼‰")
        if failed_batches:
            _log_print(f"   âš ï¸  å¤±è´¥æ‰¹æ¬¡æ•°: {len(failed_batches)}/{len(batches)}")
        _log_print()

        return creative_info, preview_info
    
    def _fetch_creative(self, ad_id: str) -> Tuple[str, Dict]:
        """è·å–å•ä¸ªå¹¿å‘Šåˆ›æ„ï¼ˆå¸¦ç¼“å­˜ä¼˜åŒ–ï¼‰"""
        # å…ˆæ£€æŸ¥ç¼“å­˜
        cached_data = self.cache.get(ad_id, 'creative')
        if cached_data is not None:
            self.cache_hits += 1
            return ad_id, cached_data
        
        self.cache_misses += 1
        
        try:
            ad = Ad(ad_id)
            ad_data = ad.api_get(fields=['creative'])

            if not ad_data.get('creative'):
                result = {'image_url': None}
                self.cache.set(ad_id, result, 'creative')
                return ad_id, result

            creative_id = ad_data['creative'].get('id')
            creative = AdCreative(creative_id)
            creative_data = creative.api_get(fields=[
                'image_url',
                'image_hash',
                'object_story_spec',
            ])

            # æå–å›¾ç‰‡URLï¼ˆå’Œtest.pyä¸€æ ·çš„é€»è¾‘ï¼‰
            image_url = creative_data.get('image_url')

            # å¦‚æœæ²¡æœ‰ç›´æ¥çš„image_urlï¼Œå°è¯•ä»object_story_specä¸­è·å–
            if not image_url:
                object_story_spec = creative_data.get('object_story_spec', {})

                # é“¾æ¥å¹¿å‘Š
                link_data = object_story_spec.get('link_data', {})
                if link_data.get('picture'):
                    image_url = link_data.get('picture')
                elif link_data.get('image_hash'):
                    img_hash = link_data.get('image_hash')
                    image_url = f"https://graph.facebook.com/{img_hash}/picture"

                # è§†é¢‘å¹¿å‘Š
                video_data = object_story_spec.get('video_data', {})
                if not image_url and video_data.get('image_url'):
                    image_url = video_data.get('image_url')

            # å¦‚æœè¿˜æ˜¯æ²¡æœ‰ï¼Œä½¿ç”¨image_hashæ„å»ºURL
            if not image_url and creative_data.get('image_hash'):
                img_hash = creative_data.get('image_hash')
                image_url = f"https://graph.facebook.com/{img_hash}/picture"

            result = {'image_url': image_url}
            # ç¼“å­˜ç»“æœ
            self.cache.set(ad_id, result, 'creative')
            return ad_id, result

        except Exception as e:
            result = {'image_url': None}
            return ad_id, result

    def _fetch_preview(self, ad_id: str) -> Tuple[str, Dict]:
        """è·å–å•ä¸ªå¹¿å‘Šé¢„è§ˆï¼ˆå¸¦ç¼“å­˜ä¼˜åŒ–ï¼‰"""
        # å…ˆæ£€æŸ¥ç¼“å­˜
        cached_data = self.cache.get(ad_id, 'preview')
        if cached_data is not None:
            self.cache_hits += 1
            return ad_id, cached_data
        
        self.cache_misses += 1
        
        try:
            ad = Ad(ad_id)
            previews = ad.get_previews(params={
                'ad_format': 'DESKTOP_FEED_STANDARD'
            })

            if previews:
                result = {'body': previews[0].get('body')}
                self.cache.set(ad_id, result, 'preview')
                return ad_id, result
            
            result = {'body': None}
            self.cache.set(ad_id, result, 'preview')
            return ad_id, result

        except Exception as e:
            result = {'body': None}
            return ad_id, result

    def concurrent_fetch(self, ad_ids: List[str], fetch_func, desc: str, max_workers: int = None) -> Dict:
        """é€šç”¨å¹¶å‘è·å–å‡½æ•°ï¼ˆæ€§èƒ½ä¼˜åŒ–ç‰ˆï¼‰"""
        if max_workers is None:
            max_workers = self.MAX_CONCURRENT_WORKERS
        
        result_dict = {}
        total = len(ad_ids)
        _log_print(f"{desc}ï¼ˆå¹¶å‘æ¨¡å¼ï¼Œ{max_workers}ä¸ªçº¿ç¨‹ï¼‰...")

        start_time = time.time()
        last_update_time = start_time

        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘è·å–
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_ad = {executor.submit(fetch_func, ad_id): ad_id
                           for ad_id in ad_ids}

            completed = 0

            # æ”¶é›†ç»“æœ
            for future in as_completed(future_to_ad):
                completed += 1
                try:
                    ad_id, data = future.result()
                    result_dict[ad_id] = data

                    # ä¼˜åŒ–è¿›åº¦æ˜¾ç¤ºï¼šæ¯ç§’æœ€å¤šæ›´æ–°ä¸€æ¬¡æˆ–æ¯50æ¡æ˜¾ç¤ºä¸€æ¬¡
                    current_time = time.time()
                    if (current_time - last_update_time >= 1.0 or 
                        completed % 50 == 0 or 
                        completed == total):
                        elapsed = current_time - start_time
                        speed = completed / elapsed if elapsed > 0 else 0
                        progress = 'â–ˆ' * int(completed/total * 30) + 'â–‘' * (30 - int(completed/total * 30))
                        _log_print(f"   [{progress}] {completed}/{total} ({completed/total*100:.1f}%) - {speed:.1f} æ¡/ç§’", end='\r')
                        last_update_time = current_time

                except Exception as e:
                    ad_id = future_to_ad[future]
                    # åªæ‰“å°å…³é”®é”™è¯¯ï¼Œé¿å…åˆ·å±
                    if completed <= 5:  # åªæ‰“å°å‰5ä¸ªé”™è¯¯
                        _log_print(f"\n   âš ï¸  è·å–å¹¿å‘Š {ad_id} å¤±è´¥: {e}")

        elapsed = time.time() - start_time
        speed = len(result_dict) / elapsed if elapsed > 0 else 0
        _log_print(f"\n   âœ… æˆåŠŸè·å– {len(result_dict)}/{total} æ¡ï¼ˆè€—æ—¶: {elapsed:.2f}ç§’ï¼Œé€Ÿåº¦: {speed:.1f} æ¡/ç§’ï¼‰\n")
        return result_dict

    def get_ad_creatives_batch(self, ad_ids: List[str]) -> Dict:
        """æ‰¹é‡è·å–å¹¿å‘Šåˆ›æ„ï¼ˆæ€§èƒ½ä¼˜åŒ–ç‰ˆï¼‰"""
        return self.concurrent_fetch(ad_ids, self._fetch_creative, "ğŸ¨ æ­£åœ¨è·å–å¹¿å‘Šåˆ›æ„ä¿¡æ¯")

    def get_ad_previews_batch(self, ad_ids: List[str]) -> Dict:
        """æ‰¹é‡è·å–å¹¿å‘Šé¢„è§ˆï¼ˆæ€§èƒ½ä¼˜åŒ–ç‰ˆï¼‰"""
        return self.concurrent_fetch(ad_ids, self._fetch_preview, "ğŸ–¼ï¸  æ­£åœ¨è·å–å¹¿å‘Šé¢„è§ˆ")
    
    def get_ad_insights(self, ad_id: str, date: str) -> Optional[Dict[str, Any]]:
        """è·å–å•ä¸ªå¹¿å‘Šåœ¨ç‰¹å®šæ—¥æœŸçš„æ•ˆæœæ•°æ®"""
        ad = Ad(ad_id)
        
        insights_data = ad.get_insights(
            fields=['impressions', 'spend', 'clicks', 'reach', 'purchase_roas', 'inline_link_clicks', 'actions'],
            params={'time_range': {'since': date, 'until': date}}
        )
        
        if not insights_data:
            return None
        
        insight = insights_data[0]
        spend = float(insight.get('spend', 0))
        purchase_roas = self._extract_purchase_roas(insight)
        actions = self._extract_actions(insight)
        
        return {
            'impressions': int(insight.get('impressions', 0)),
            'spend': spend,
            'clicks': int(insight.get('clicks', 0)),
            'reach': int(insight.get('reach', 0)),
            'purchase_roas': purchase_roas,
            'purchase_conversion_value': round(spend * purchase_roas, 2),
            'inline_link_clicks': int(insight.get('inline_link_clicks', 0)),
            **actions
        }
    
    def get_ad_insights_with_retry(
        self, 
        ad_id: str, 
        date: str, 
        max_retries: int = 3
    ) -> Optional[Dict[str, Any]]:
        """è·å–å¹¿å‘Šæ•ˆæœæ•°æ®ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰"""
        for attempt in range(max_retries):
            try:
                return self.get_ad_insights(ad_id, date)
            except FacebookRequestError as e:
                if e.http_status() == 403 and e.api_error_code() == 4:
                    wait_time = (2 ** attempt) * 10
                    _log_print(f"APIé™åˆ¶ï¼Œç­‰å¾… {wait_time}ç§’ (å°è¯• {attempt + 1}/{max_retries})")
                    time.sleep(wait_time)
                else:
                    raise
            except Exception as e:
                if attempt < max_retries - 1:
                    wait_time = (2 ** attempt) * 5
                    _log_print(f"é”™è¯¯: {e}ï¼Œ{wait_time}ç§’åé‡è¯•")
                    time.sleep(wait_time)
                else:
                    _log_print(f"è·å–å¹¿å‘Š {ad_id} åœ¨ {date} çš„æ•°æ®å¤±è´¥: {e}")
                    return None
        return None
    
    def _convert_to_tuple(self, row: Dict, date: str, account_id: str = None) -> Tuple:
        """
        è½¬æ¢æ•°æ®å­—å…¸ä¸ºå…ƒç»„æ ¼å¼ï¼ˆAd çº§åˆ«æ•°æ®ï¼‰
        
        row åº”åŒ…å«ï¼š
        - campaign_id, adset_id, ad_id
        - campaign_name, adset_name, ad_name
        """
        return (
            row['campaign_id'], row['adset_id'], row['ad_id'],
            account_id,
            row['campaign_name'], row['adset_name'], row['ad_name'],
            row['impressions'], row['spend'], row['clicks'],
            row['purchase_roas'], row['reach'], row['inline_link_clicks'],
            row['add_to_cart'], row['add_payment_info'], row['purchase'],
            date
        )
    
    def _generate_date_list(self, start_date: str, end_date: str) -> List[str]:
        """ç”Ÿæˆæ—¥æœŸèŒƒå›´å†…çš„æ‰€æœ‰æ—¥æœŸåˆ—è¡¨"""
        start = datetime.strptime(start_date, '%Y-%m-%d')
        end = datetime.strptime(end_date, '%Y-%m-%d')
        date_list = []
        current = start
        while current <= end:
            date_list.append(current.strftime('%Y-%m-%d'))
            current += timedelta(days=1)
        return date_list
    
    def _fetch_single_ad_date(
        self, 
        ad_id: str,
        ad_name: str,
        adset_id: str,
        adset_name: str,
        campaign_id: str,
        campaign_name: str,
        date: str,
        account_id: str = None
    ) -> Optional[Tuple]:
        """
        è·å–å•ä¸ªå¹¿å‘Šåœ¨ç‰¹å®šæ—¥æœŸçš„æ•°æ®ï¼ˆç”¨äºå¹¶å‘å¤„ç†ï¼‰
        
        Args:
            ad_id: å¹¿å‘ŠID
            ad_name: å¹¿å‘Šåç§°
            adset_id: å¹¿å‘Šç»„ID
            adset_name: å¹¿å‘Šç»„åç§°
            campaign_id: å¹¿å‘Šç³»åˆ—ID
            campaign_name: å¹¿å‘Šç³»åˆ—åç§°
            date: æ—¥æœŸ
            account_id: å¹¿å‘Šè´¦æˆ·ID
            
        Returns:
            æ•°æ®å…ƒç»„æˆ–None
        """
        try:
            # éªŒè¯å¿…è¦çš„ ID
            if not ad_id or not adset_id or not campaign_id:
                _log_print(f"   âš ï¸  è·³è¿‡ {ad_name}: ç¼ºå°‘å¿…è¦çš„ ID ä¿¡æ¯")
                return None
            
            insights = self.get_ad_insights_with_retry(ad_id, date)
            if insights:
                data_row = {
                    'campaign_id': campaign_id,
                    'campaign_name': campaign_name,
                    'adset_id': adset_id,
                    'adset_name': adset_name,
                    'ad_id': ad_id,
                    'ad_name': ad_name,
                    **insights
                }
                return self._convert_to_tuple(data_row, date, account_id)
        except Exception as e:
            _log_print(f"   âš ï¸  è·³è¿‡ {ad_name} ({date}): {e}")
        return None
    
    def _fetch_ads_data_in_batches(
        self,
        start_date: str,
        end_date: str,
        account_id: str = None,
        limit: int = None,
        days_per_batch: int = 7
    ) -> Tuple[bool, List[Tuple], str]:
        """
        åˆ†æ‰¹è·å–å¹¿å‘Šæ•°æ®ï¼ˆç”¨äºå¤§æ—¥æœŸèŒƒå›´ï¼‰
        
        Args:
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            account_id: å¹¿å‘Šè´¦æˆ·ID
            limit: é™åˆ¶è·å–çš„å¹¿å‘Šæ•°é‡
            days_per_batch: æ¯æ‰¹å¤„ç†çš„å¤©æ•°
            
        Returns:
            (æˆåŠŸæ ‡å¿—, æ•°æ®åˆ—è¡¨, é”™è¯¯ä¿¡æ¯)
        """
        all_data_tuples = []
        all_ad_ids = set()
        
        start_dt = datetime.strptime(start_date, '%Y-%m-%d')
        end_dt = datetime.strptime(end_date, '%Y-%m-%d')
        
        current_start = start_dt
        batch_num = 1
        
        while current_start <= end_dt:
            # è®¡ç®—å½“å‰æ‰¹æ¬¡çš„ç»“æŸæ—¥æœŸ
            current_end = min(current_start + timedelta(days=days_per_batch - 1), end_dt)
            
            batch_start_str = current_start.strftime('%Y-%m-%d')
            batch_end_str = current_end.strftime('%Y-%m-%d')
            
            _log_print(f"\nğŸ“¦ æ‰¹æ¬¡ {batch_num}: {batch_start_str} åˆ° {batch_end_str}")
            
            # è·å–å½“å‰æ‰¹æ¬¡çš„æ•°æ®
            success, batch_data, error_msg = self._fetch_single_batch(
                batch_start_str, 
                batch_end_str, 
                account_id, 
                limit
            )
            
            if not success:
                _log_print(f"   âš ï¸  æ‰¹æ¬¡ {batch_num} å¤±è´¥: {error_msg}")
                # ç»§ç»­å¤„ç†ä¸‹ä¸€æ‰¹æ¬¡ï¼Œä¸ä¸­æ–­æ•´ä¸ªæµç¨‹
            else:
                all_data_tuples.extend(batch_data)
                _log_print(f"   âœ… æ‰¹æ¬¡ {batch_num} å®Œæˆ: è·å– {len(batch_data)} æ¡è®°å½•")
            
            # ç§»åŠ¨åˆ°ä¸‹ä¸€æ‰¹æ¬¡
            current_start = current_end + timedelta(days=1)
            batch_num += 1
        
        if not all_data_tuples:
            return False, [], "æ‰€æœ‰æ‰¹æ¬¡å‡æœªè·å–åˆ°æ•°æ®"
        
        _log_print(f"\nâœ… æ‰€æœ‰æ‰¹æ¬¡å¤„ç†å®Œæˆï¼Œå…±è·å– {len(all_data_tuples)} æ¡è®°å½•")
        return True, all_data_tuples, ""
    
    def _fetch_single_batch(
        self,
        start_date: str,
        end_date: str,
        account_id: str = None,
        limit: int = None
    ) -> Tuple[bool, List[Tuple], str]:
        """
        è·å–å•ä¸ªæ‰¹æ¬¡çš„æ•°æ®ï¼ˆå†…éƒ¨æ–¹æ³•ï¼‰
        
        Args:
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            account_id: å¹¿å‘Šè´¦æˆ·ID
            limit: é™åˆ¶è·å–çš„å¹¿å‘Šæ•°é‡
            
        Returns:
            (æˆåŠŸæ ‡å¿—, æ•°æ®åˆ—è¡¨, é”™è¯¯ä¿¡æ¯)
        """
        try:
            # è·å–å¹¿å‘Šinsights
            insights = self.ad_account.get_insights(
                fields=[
                    'ad_id',
                    'ad_name',
                    'adset_id',
                    'adset_name',
                    'campaign_id',
                    'campaign_name',
                    'impressions',
                    'spend',
                    'clicks',
                    'reach',
                    'actions',
                    'unique_actions',
                    'action_values',
                    'purchase_roas'
                ],
                params={
                    'level': 'ad',
                    'time_range': {
                        'since': start_date,
                        'until': end_date
                    },
                    'time_increment': 1,
                    'filtering': [
                        {
                            'field': 'spend',
                            'operator': 'GREATER_THAN',
                            'value': 0
                        }
                    ],
                    'limit': limit if limit else 1000
                }
            )
            
            # å¤„ç†æ•°æ®
            ads_list = []
            ad_ids_set = set()
            
            for insight in insights:
                try:
                    spend = float(insight.get('spend', 0))
                    if spend == 0:
                        continue
                    
                    ad_id = insight.get('ad_id')
                    ad_ids_set.add(ad_id)
                    
                    actions = {act.get('action_type'): int(act.get('value', 0))
                              for act in insight.get('actions', [])}
                    unique_actions = {act.get('action_type'): int(act.get('value', 0))
                                     for act in insight.get('unique_actions', [])}
                    
                    purchase_roas = self._extract_purchase_roas(insight)
                    date = insight.get('date_start')
                    
                    ad_data = {
                        'ad_id': ad_id,
                        'ad_name': insight.get('ad_name'),
                        'adset_id': insight.get('adset_id'),
                        'adset_name': insight.get('adset_name'),
                        'campaign_id': insight.get('campaign_id'),
                        'campaign_name': insight.get('campaign_name'),
                        'impressions': int(insight.get('impressions', 0)),
                        'spend': spend,
                        'clicks': int(insight.get('clicks', 0)),
                        'reach': int(insight.get('reach', 0)),
                        'purchase_roas': purchase_roas,
                        'purchase': actions.get('purchase', 0),
                        'add_to_cart': actions.get('add_to_cart', 0),
                        'add_payment_info': actions.get('add_payment_info', 0),
                        'unique_link_click': unique_actions.get('link_click', 0),
                        'date': date
                    }
                    
                    ads_list.append(ad_data)
                    
                except Exception as e:
                    continue
            
            if not ads_list:
                return True, [], ""
            
            # è·å–åˆ›æ„å’Œé¢„è§ˆä¿¡æ¯
            ad_ids = list(ad_ids_set)
            
            if self.USE_BATCH_API:
                creative_info, preview_info = self.get_batch_creatives_and_previews(ad_ids)
            else:
                creative_info = self.get_ad_creatives_batch(ad_ids)
                if self.ENABLE_PREVIEW:
                    preview_info = self.get_ad_previews_batch(ad_ids)
                else:
                    preview_info = {}
            
            # ç”Ÿæˆæ•°æ®è®°å½•
            all_data_tuples = []
            for ad_data in ads_list:
                ad_id = ad_data['ad_id']
                image_url = creative_info.get(ad_id, {}).get('image_url')
                preview_body = preview_info.get(ad_id, {}).get('body') if preview_info else None
                
                all_data_tuples.append((
                    ad_data['campaign_id'],
                    ad_data['adset_id'],
                    ad_data['ad_id'],
                    account_id,
                    ad_data['campaign_name'],
                    ad_data['adset_name'],
                    ad_data['ad_name'],
                    ad_data['impressions'],
                    ad_data['spend'],
                    ad_data['clicks'],
                    ad_data['purchase_roas'],
                    ad_data['reach'],
                    ad_data['unique_link_click'],
                    ad_data['add_to_cart'],
                    ad_data['add_payment_info'],
                    ad_data['purchase'],
                    image_url,           # 17. image_url
                    preview_body,        # 18. preview_url
                    ad_data['date']      # 19. createtime (æ—¥æœŸ)
                ))
            
            return True, all_data_tuples, ""
            
        except FacebookRequestError as e:
            error_msg = f"APIè¯·æ±‚å¤±è´¥ (ä»£ç : {e.api_error_code()}): {e.api_error_message()}"
            return False, [], error_msg
        except Exception as e:
            error_msg = f"è·å–æ•°æ®å¤±è´¥: {str(e)}"
            return False, [], error_msg
    
    def fetch_ads_data_optimized(
        self, 
        start_date: str, 
        end_date: str, 
        account_id: str = None,
        limit: int = None
    ) -> Tuple[bool, List[Tuple], str]:
        """
        ä» Facebook Ads API è·å–å¹¿å‘Šæ•°æ®ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ - æ”¯æŒæ—¥æœŸåˆ†ç‰‡ï¼‰
        ä½¿ç”¨è´¦æˆ·çº§åˆ«çš„ Insights API è·å–å¹¿å‘Šæ•°æ®ï¼Œè‡ªåŠ¨å°†å¤§çš„æ—¥æœŸèŒƒå›´åˆ†å‰²æˆå°æ‰¹æ¬¡
        
        Args:
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            account_id: å¹¿å‘Šè´¦æˆ·ID
            limit: é™åˆ¶è·å–çš„å¹¿å‘Šæ•°é‡ï¼ˆNoneè¡¨ç¤ºè·å–å…¨éƒ¨ï¼‰
            
        Returns:
            (æˆåŠŸæ ‡å¿—, æ•°æ®åˆ—è¡¨, é”™è¯¯ä¿¡æ¯)
        """
        if not self.api_initialized or not self.ad_account:
            return False, [], "Facebook API æœªåˆå§‹åŒ–"
        
        try:
            # è®¡ç®—æ—¥æœŸèŒƒå›´å¤©æ•°
            start_dt = datetime.strptime(start_date, '%Y-%m-%d')
            end_dt = datetime.strptime(end_date, '%Y-%m-%d')
            total_days = (end_dt - start_dt).days + 1
            
            # å¦‚æœæ—¥æœŸèŒƒå›´è¶…è¿‡7å¤©ï¼Œåˆ†æ‰¹å¤„ç†ï¼ˆæ¯æ‰¹7å¤©ï¼‰
            MAX_DAYS_PER_BATCH = 7
            
            if total_days > MAX_DAYS_PER_BATCH:
                _log_print(f"ğŸ“† æ—¥æœŸèŒƒå›´è¾ƒå¤§ï¼ˆ{total_days}å¤©ï¼‰ï¼Œå°†åˆ†æˆ {(total_days + MAX_DAYS_PER_BATCH - 1) // MAX_DAYS_PER_BATCH} æ‰¹å¤„ç†...")
                return self._fetch_ads_data_in_batches(start_date, end_date, account_id, limit, MAX_DAYS_PER_BATCH)
            
            # ä½¿ç”¨è´¦æˆ·çº§åˆ«çš„insights APIï¼Œè·å–å¹¿å‘Šçš„æ•ˆæœæ•°æ®
            _log_print("âš¡ æ­£åœ¨æ‰¹é‡è·å–å¹¿å‘Šæ•ˆæœæ•°æ®...")
            self.perf_stats.start_timer("è·å– Insights æ•°æ®")

            # è·å–å¹¿å‘Šinsightsï¼ˆAdçº§åˆ«ï¼‰
            insights = self.ad_account.get_insights(
                fields=[
                    'ad_id',
                    'ad_name',
                'adset_id',
                    'adset_name',
                'campaign_id',
                    'campaign_name',
                    'impressions',
                    'spend',
                    'clicks',
                    'reach',
                    'actions',
                    'unique_actions',  # ç‹¬ç«‹æ“ä½œï¼ˆåŒ…æ‹¬ç‹¬ç«‹é“¾æ¥ç‚¹å‡»ï¼‰
                    'action_values',
                    'purchase_roas'
                ],
                params={
                    'level': 'ad',  # è·å–å¹¿å‘Šçº§åˆ«çš„æ•°æ®
                    'time_range': {
                        'since': start_date,
                        'until': end_date
                    },
                    'time_increment': 1,  # æŒ‰å¤©è¿”å›æ•°æ®ï¼ˆé‡è¦ï¼ï¼‰
                    'filtering': [
                        {
                            'field': 'spend',
                            'operator': 'GREATER_THAN',
                            'value': 0
                        }
                    ],
                    'limit': limit if limit else 1000  # é™åˆ¶è·å–æ¡æ•°
                }
            )

            self.perf_stats.end_timer("è·å– Insights æ•°æ®")

            _log_print("ğŸ“¥ æ­£åœ¨å¤„ç†æ•°æ®...")
            self.perf_stats.start_timer("å¤„ç† Insights æ•°æ®")

            ads_list = []
            ad_ids_set = set()  # ä½¿ç”¨setæ”¶é›†å”¯ä¸€çš„ad_idç”¨äºè·å–åˆ›æ„å’Œé¢„è§ˆ
            all_data_tuples = []
            total_spend = 0

            # å¤„ç†æ‰€æœ‰insightsæ•°æ®
            # æ³¨æ„ï¼šæ·»åŠ äº†time_increment: 1åï¼ŒAPIä¼šä¸ºæ¯ä¸ªå¹¿å‘Šçš„æ¯ä¸€å¤©è¿”å›ä¸€æ¡è®°å½•
            # ä¾‹å¦‚ï¼š7å¤©æ•°æ®ï¼Œæ¯ä¸ªå¹¿å‘Šä¼šè¿”å›7æ¡è®°å½•
            for i, insight in enumerate(insights, 1):
                try:
                    # æå–èŠ±è´¹
                    spend = float(insight.get('spend', 0))

                    # åªå¤„ç†èŠ±è´¹å¤§äº0çš„å¹¿å‘Š
                    if spend == 0:
                        continue

                    total_spend += spend
                    ad_id = insight.get('ad_id')
                    ad_ids_set.add(ad_id)  # æ”¶é›†å”¯ä¸€çš„ad_id

                    # æå–actionsæ•°æ®
                    actions = {act.get('action_type'): int(act.get('value', 0))
                              for act in insight.get('actions', [])}
                    unique_actions = {act.get('action_type'): int(act.get('value', 0))
                                     for act in insight.get('unique_actions', [])}

                    # æå–purchase_roas
                    purchase_roas = self._extract_purchase_roas(insight)

                    # è·å–æ—¥æœŸï¼ˆAPIè¿”å›çš„date_startå­—æ®µï¼‰
                    date = insight.get('date_start')  # æ ¼å¼ï¼šYYYY-MM-DD

                    # ç»„è£…å¹¿å‘Šæ•°æ®ï¼ˆåŒ…å«æ—¥æœŸï¼‰
                    ad_data = {
                        'ad_id': ad_id,
                        'ad_name': insight.get('ad_name'),
                        'adset_id': insight.get('adset_id'),
                        'adset_name': insight.get('adset_name'),
                        'campaign_id': insight.get('campaign_id'),
                        'campaign_name': insight.get('campaign_name'),
                        'impressions': int(insight.get('impressions', 0)),
                        'spend': spend,
                        'clicks': int(insight.get('clicks', 0)),
                        'reach': int(insight.get('reach', 0)),
                        'purchase_roas': purchase_roas,
                        'purchase': actions.get('purchase', 0),
                        'add_to_cart': actions.get('add_to_cart', 0),
                        'add_payment_info': actions.get('add_payment_info', 0),
                        'unique_link_click': unique_actions.get('link_click', 0),
                        'date': date  # æ·»åŠ æ—¥æœŸå­—æ®µ
                    }

                    ads_list.append(ad_data)

                    # æ¯å¤„ç†100æ¡æ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
                    if i % 100 == 0:
                        _log_print(f"   å·²å¤„ç† {i} æ¡å¹¿å‘Šæ•°æ®...")

                except Exception as e:
                    _log_print(f"   âš ï¸  å¤„ç†ç¬¬ {i} æ¡æ•°æ®æ—¶å‡ºé”™: {e}")
                    continue
                
            self.perf_stats.end_timer("å¤„ç† Insights æ•°æ®")
            
            # è½¬æ¢ä¸ºåˆ—è¡¨ç”¨äºè·å–åˆ›æ„å’Œé¢„è§ˆ
            ad_ids = list(ad_ids_set)

            # è·å–å¹¿å‘Šåˆ›æ„å’Œé¢„è§ˆä¿¡æ¯
            if ads_list and ad_ids:
                _log_print()

                # å¯åŠ¨æ€§èƒ½è®¡æ—¶
                self.perf_stats.start_timer("è·å–åˆ›æ„å’Œé¢„è§ˆ")

                if self.USE_BATCH_API:
                    # ä½¿ç”¨Batch APIåŒæ—¶è·å–åˆ›æ„å’Œé¢„è§ˆï¼ˆæœ€å¿«æ–¹å¼ï¼‰
                    creative_info, preview_info = self.get_batch_creatives_and_previews(ad_ids)
                else:
                    # ä½¿ç”¨ä¼ ç»Ÿå¹¶å‘æ–¹å¼åˆ†åˆ«è·å–
                    creative_info = self.get_ad_creatives_batch(ad_ids)
                    if self.ENABLE_PREVIEW:
                        preview_info = self.get_ad_previews_batch(ad_ids)
                    else:
                        preview_info = {}

                self.perf_stats.end_timer("è·å–åˆ›æ„å’Œé¢„è§ˆ")

                # å°†åˆ›æ„å’Œé¢„è§ˆä¿¡æ¯åˆå¹¶åˆ°å¹¿å‘Šæ•°æ®ä¸­ï¼Œç”Ÿæˆæœ€ç»ˆæ•°æ®è®°å½•
                _log_print("ğŸ“ æ­£åœ¨ç”Ÿæˆæ•°æ®è®°å½•...")
                self.perf_stats.start_timer("ç”Ÿæˆæ•°æ®è®°å½•")
                
                # åˆå§‹åŒ–æ•°æ®åˆ—è¡¨
                all_data_tuples = []
                
                # æ‰¹é‡å¤„ç†ï¼Œå‡å°‘å¾ªç¯å¼€é”€
                # æ³¨æ„ï¼šads_listä¸­çš„æ¯æ¡è®°å½•å·²ç»åŒ…å«äº†å…·ä½“çš„æ—¥æœŸï¼ˆdateå­—æ®µï¼‰
                for ad_data in ads_list:
                    ad_id = ad_data['ad_id']
                    
                    # è·å–å›¾ç‰‡URLå’Œé¢„è§ˆï¼ˆä½¿ç”¨ get æ–¹æ³•é¿å…å¤šæ¬¡æŸ¥æ‰¾ï¼‰
                    image_url = creative_info.get(ad_id, {}).get('image_url')
                    preview_body = preview_info.get(ad_id, {}).get('body') if preview_info else None
                    
                    # åˆ›å»ºä¸€æ¡è®°å½•ï¼ˆä¸éœ€è¦å¾ªç¯æ—¥æœŸï¼Œå› ä¸ºæ•°æ®å·²ç»æŒ‰å¤©åˆ†å¼€äº†ï¼‰
                    all_data_tuples.append((
                        ad_data['campaign_id'],
                        ad_data['adset_id'],
                        ad_data['ad_id'],
                        account_id,
                        ad_data['campaign_name'],
                        ad_data['adset_name'],
                        ad_data['ad_name'],
                        ad_data['impressions'],
                        ad_data['spend'],
                        ad_data['clicks'],
                        ad_data['purchase_roas'],
                        ad_data['reach'],
                        ad_data['unique_link_click'],
                        ad_data['add_to_cart'],
                        ad_data['add_payment_info'],
                        ad_data['purchase'],
                        image_url,
                        preview_body,
                        ad_data['date']  # ä½¿ç”¨APIè¿”å›çš„å…·ä½“æ—¥æœŸ
                    ))
                
                self.perf_stats.end_timer("ç”Ÿæˆæ•°æ®è®°å½•")

            _log_print(f"\nâœ… æ•°æ®è·å–å®Œæˆï¼")
            _log_print(f"å”¯ä¸€å¹¿å‘Šæ•°: {len(ad_ids)}")
            _log_print(f"æ•°æ®è®°å½•æ•°: {len(ads_list)} (åŒ…å«æ¯å¤©çš„æ•°æ®)")
            _log_print(f"æ€»èŠ±è´¹: ${total_spend:.2f}")
            _log_print(f"ç”Ÿæˆæ•°æ®åº“è®°å½•æ•°: {len(all_data_tuples)}")

            return True, all_data_tuples, ""
            
        except FacebookRequestError as e:
            if e.api_error_code() == 17:
                error_msg = f"é‡åˆ°APIé€Ÿç‡é™åˆ¶: {e.api_error_message()}"
                _log_print(f"\nâŒ {error_msg}")
                _log_print(f"   å»ºè®®ç­‰å¾… 5-10 åˆ†é’Ÿåå†è¯•")
            else:
                error_msg = f"APIè¯·æ±‚å¤±è´¥ (ä»£ç : {e.api_error_code()}): {e.api_error_message()}"
                _log_print(f"\nâŒ {error_msg}")
            return False, [], error_msg
        except Exception as e:
            error_msg = f"è·å–å¹¿å‘Šæ•°æ®å¤±è´¥: {str(e)}"
            _log_print(f"\nâŒ {error_msg}")
            import traceback
            traceback.print_exc()
            return False, [], error_msg
    
    def delete_data_in_range(self, start_date: str, end_date: str, account_id: str = None) -> None:
        """
        åˆ é™¤æŒ‡å®šæ—¥æœŸèŒƒå›´å’Œè´¦æˆ·çš„æ•°æ®
        
        Args:
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            account_id: è´¦æˆ·IDï¼ˆå¯é€‰ï¼‰
        """
        if account_id:
            delete_query = text(
                f"DELETE FROM {self.table_name} WHERE createtime BETWEEN :start_date AND :end_date AND account_id = :account_id"
            )
            self.db.execute(delete_query, {"start_date": start_date, "end_date": end_date, "account_id": account_id})
            _log_print(f"ğŸ—‘ï¸  å·²åˆ é™¤è´¦æˆ· {account_id} æ—¥æœŸèŒƒå›´ {start_date} åˆ° {end_date} çš„æ•°æ®")
        else:
            # å¦‚æœæ²¡æœ‰æŒ‡å®šè´¦æˆ·IDï¼Œè°ƒç”¨çˆ¶ç±»æ–¹æ³•
            super().delete_data_in_range(start_date, end_date)
    
    def insert_data(self, data_list: List[Tuple], start_date: str, end_date: str, account_id: str = None) -> Tuple[bool, int, str]:
        """æ‰¹é‡æ’å…¥æ•°æ®ï¼ˆæ’å…¥å‰å…ˆåˆ é™¤æŒ‡å®šæ—¥æœŸåŒºé—´å’Œè´¦æˆ·çš„æ•°æ®ï¼‰"""
        if not data_list:
            return True, 0, "æ²¡æœ‰æ•°æ®éœ€è¦æ’å…¥"
        
        try:
            # åˆ é™¤æŒ‡å®šæ—¥æœŸåŒºé—´å’Œè´¦æˆ·çš„æ•°æ®
            self.delete_data_in_range(start_date, end_date, account_id)
            
            # æ‰¹é‡æ’å…¥æ–°æ•°æ®ï¼ˆåŒ…æ‹¬ image_url å’Œ preview_urlï¼‰
            insert_query = text("""
                INSERT INTO fact_bi_ads_facebook_campaign (
                    campaign_id, adset_id, ad_id, account_id,
                    campaign_name, adset_name, ad_name,
                    impression, spend, clicks, 
                    purchases_roas, reach, unique_link_clicks, adds_to_cart, 
                    adds_payment_info, purchases, image_url, preview_url, createtime
                )
                VALUES (
                    :campaign_id, :adset_id, :ad_id, :account_id,
                    :campaign_name, :adset_name, :ad_name,
                    :impression, :spend, :clicks,
                    :purchases_roas, :reach, :unique_link_clicks, :adds_to_cart,
                    :adds_payment_info, :purchases, :image_url, :preview_url, :createtime
                )
            """)
            
            data_dicts = []
            for r in data_list:
                # ç¡®ä¿æ•°æ®ç»“æ„æ­£ç¡®
                if len(r) >= 19:
                    # æ–°æ ¼å¼ï¼šåŒ…å« image_url å’Œ preview_url
                    data_dict = {
                        'campaign_id': r[0], 'adset_id': r[1], 'ad_id': r[2], 'account_id': r[3],
                        'campaign_name': r[4], 'adset_name': r[5], 'ad_name': r[6],
                        'impression': r[7], 'spend': r[8], 'clicks': r[9],
                        'purchases_roas': r[10], 'reach': r[11], 'unique_link_clicks': r[12],
                        'adds_to_cart': r[13], 'adds_payment_info': r[14], 'purchases': r[15],
                        'image_url': r[16],
                        'preview_url': r[17],
                        'createtime': r[18]
                    }
                elif len(r) == 17:
                    # æ—§æ ¼å¼ï¼šä¸åŒ…å« image_url å’Œ preview_url
                    data_dict = {
                        'campaign_id': r[0], 'adset_id': r[1], 'ad_id': r[2], 'account_id': r[3],
                        'campaign_name': r[4], 'adset_name': r[5], 'ad_name': r[6],
                        'impression': r[7], 'spend': r[8], 'clicks': r[9],
                        'purchases_roas': r[10], 'reach': r[11], 'unique_link_clicks': r[12],
                        'adds_to_cart': r[13], 'adds_payment_info': r[14], 'purchases': r[15],
                        'image_url': None,
                        'preview_url': None,
                        'createtime': r[16]
                    }
                else:
                    _log_print(f"   âš ï¸  è­¦å‘Š: æ•°æ®é•¿åº¦å¼‚å¸¸ (é•¿åº¦={len(r)}), è·³è¿‡æ­¤æ¡")
                    continue
                
                data_dicts.append(data_dict)
            
            count = self.batch_insert(insert_query, data_dicts, batch_size=self.DB_BATCH_SIZE)
            return True, count, ""
            
        except Exception as e:
            error_msg = f"æ’å…¥æ•°æ®å¤±è´¥: {str(e)}"
            _log_print(f"âŒ {error_msg}")
            self.db.rollback()
            return False, 0, error_msg
    
    def _create_error_result(self, message: str, error: str = None) -> Dict[str, Any]:
        """åˆ›å»ºé”™è¯¯ç»“æœå­—å…¸"""
        return self.create_sync_result(False, message, 0, [error or message])
    
    def sync_ads(
        self,
        access_token: str,
        ad_account_id: str,
        start_date: str,
        end_date: str,
        max_workers: int = 10,
        account_id_for_db: str = None,
        limit: int = None,
        proxy_url: str = None
    ) -> Dict[str, Any]:
        """
        åŒæ­¥å¹¿å‘Šæ•°æ®ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼‰
        
        Args:
            access_token: Facebookè®¿é—®ä»¤ç‰Œ
            ad_account_id: å¹¿å‘Šè´¦æˆ·IDï¼ˆå¸¦act_å‰ç¼€ï¼Œç”¨äºè°ƒç”¨Facebook APIï¼‰
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            max_workers: å¹¶å‘çº¿ç¨‹æ•°ï¼ˆé»˜è®¤10ï¼Œç”¨äºfallbackæ¨¡å¼ï¼‰
            account_id_for_db: è´¦æˆ·IDï¼ˆä¸å¸¦act_å‰ç¼€ï¼Œç”¨äºä¿å­˜åˆ°æ•°æ®åº“ï¼‰
            limit: é™åˆ¶è·å–çš„å¹¿å‘Šæ•°é‡ï¼ˆNoneè¡¨ç¤ºè·å–å…¨éƒ¨ï¼‰
            
        Returns:
            åŒæ­¥ç»“æœ
            
        æ³¨æ„: ä¼šè‡ªåŠ¨è¦†ç›–æŒ‡å®šæ—¥æœŸèŒƒå›´å†…çš„ç°æœ‰æ•°æ®
        
        æ€§èƒ½ä¼˜åŒ–ï¼š
        - ä½¿ç”¨è´¦æˆ·çº§åˆ« Insights API ä¸€æ¬¡æ€§è·å–æ‰€æœ‰å¹¿å‘Šæ•°æ®ï¼ˆé€Ÿåº¦å¿«10-15å€ï¼‰
        - ä½¿ç”¨ Batch API æ‰¹é‡è·å–åˆ›æ„å’Œé¢„è§ˆï¼ˆå‡å°‘90%çš„APIè°ƒç”¨ï¼‰
        - æ”¯æŒè·å–å›¾ç‰‡URLå’Œå¹¿å‘Šé¢„è§ˆä¿¡æ¯
        """
        start_time = time.time()
        
        _log_print(f"\n{'='*60}")
        _log_print(f"ğŸš€ å¼€å§‹åŒæ­¥ Facebook Ads æ•°æ®ï¼ˆé«˜æ€§èƒ½ç‰ˆæœ¬ v2.0ï¼‰")
        _log_print(f"ğŸ“… æ—¥æœŸèŒƒå›´: {start_date} åˆ° {end_date}")
        _log_print(f"âš™ï¸  æ€§èƒ½é…ç½®: {self.performance_profile.upper()}")
        _log_print(f"{'â”€'*60}")
        _log_print(f"ğŸ”§ ä¼˜åŒ–æ¨¡å¼: {'Batch API' if self.USE_BATCH_API else f'é«˜å¹¶å‘çº¿ç¨‹æ±  ({self.MAX_CONCURRENT_WORKERS} çº¿ç¨‹)'}")
        _log_print(f"ğŸ“¸ è·å–é¢„è§ˆ: {'æ˜¯' if self.ENABLE_PREVIEW else 'å¦'}")
        _log_print(f"ğŸŒ HTTPè¿æ¥æ± : {self.CONNECTION_POOL_SIZE} è¿æ¥ | è¶…æ—¶: {self.REQUEST_TIMEOUT}ç§’")
        _log_print(f"ğŸ’¾ æ•°æ®åº“æ‰¹æ¬¡: {self.DB_BATCH_SIZE} æ¡/æ‰¹")
        _log_print(f"ğŸ’¿ ç¼“å­˜TTL: {self.CACHE_TTL}ç§’ ({self.CACHE_TTL//3600}å°æ—¶)")
        _log_print(f"âš ï¸  æ³¨æ„: å°†è¦†ç›–æ­¤æ—¥æœŸèŒƒå›´å†…çš„ç°æœ‰æ•°æ®")
        _log_print(f"{'='*60}\n")

        # è®¾ç½®ä»£ç†ï¼ˆå¦‚æœæä¾›ï¼‰
        self.setup_proxy(proxy_url)
        
        # åˆå§‹åŒ– API
        if not self.initialize_api(access_token, ad_account_id):
            return self._create_error_result("Facebook API åˆå§‹åŒ–å¤±è´¥")
        
        # è·å–æ•°æ®ï¼ˆä½¿ç”¨ä¼˜åŒ–ç‰ˆæœ¬ï¼‰
        _log_print("\nğŸ“¡ ä» Facebook Ads API è·å–å¹¿å‘Šæ•°æ®...")
        # ç¡®å®šä¿å­˜åˆ°æ•°æ®åº“çš„è´¦æˆ·IDï¼ˆä¸å¸¦å‰ç¼€ï¼‰
        final_account_id_for_db = account_id_for_db if account_id_for_db else ad_account_id.replace('act_', '')
        
        success, data_list, error_msg = self.fetch_ads_data_optimized(
            start_date, end_date, final_account_id_for_db, limit
        )
        
        if not success:
            return self._create_error_result(error_msg or "è·å–æ•°æ®å¤±è´¥", error_msg)
        
        _log_print(f"âœ… æˆåŠŸè·å– {len(data_list)} æ¡å¹¿å‘Šæ•°æ®")
        
        # æ’å…¥æ•°æ®
        _log_print("\nğŸ’¾ å†™å…¥æ•°æ®åº“...")
        self.perf_stats.start_timer("æ•°æ®åº“æ’å…¥")
        success, count, error_msg = self.insert_data(data_list, start_date, end_date, final_account_id_for_db)
        self.perf_stats.end_timer("æ•°æ®åº“æ’å…¥")
        
        if not success:
            return self._create_error_result(error_msg or "æ’å…¥æ•°æ®å¤±è´¥", error_msg)
        
        elapsed_time = time.time() - start_time
        
        _log_print(f"\n{'='*60}")
        _log_print(f"âœ… Facebook Ads æ•°æ®åŒæ­¥å®Œæˆï¼")
        _log_print(f"ğŸ“Š å…±åŒæ­¥ {count} æ¡å¹¿å‘Šè®°å½•ï¼ˆåŒ…å«æ¯å¤©çš„æ•°æ®ï¼‰")
        _log_print(f"â±ï¸  æ€»è€—æ—¶: {elapsed_time:.2f} ç§’")
        _log_print(f"âš¡ å¹³å‡é€Ÿåº¦: {count/elapsed_time:.2f} æ¡/ç§’")
        _log_print(f"ğŸ”§ ä¼˜åŒ–æ¨¡å¼: {'Batch API' if self.USE_BATCH_API else f'é«˜å¹¶å‘çº¿ç¨‹æ±  ({self.MAX_CONCURRENT_WORKERS} çº¿ç¨‹)'}")
        
        # æ€§èƒ½æç¤º
        if elapsed_time > 0 and count > 0:
            date_count = len(self._generate_date_list(start_date, end_date))
            unique_ads_count = count // date_count if date_count > 0 else count
            _log_print(f"ğŸ“ˆ æ€§èƒ½æŒ‡æ ‡: çº¦ {unique_ads_count} ä¸ªå”¯ä¸€å¹¿å‘Š Ã— {date_count} å¤©")
            
        # æ€§èƒ½ä¼˜åŒ–å»ºè®®
        if not self.ENABLE_PREVIEW:
            _log_print(f"ğŸ’¡ æç¤º: å·²ç¦ç”¨é¢„è§ˆï¼Œå¦‚éœ€é¢„è§ˆè¯·è®¾ç½® ENABLE_PREVIEW = True")
        
        _log_print(f"{'='*60}\n")
        
        # æ˜¾ç¤ºæ€§èƒ½ç»Ÿè®¡
        self.perf_stats.print_summary()
        
        # æ˜¾ç¤ºç¼“å­˜ç»Ÿè®¡
        total_cache_requests = self.cache_hits + self.cache_misses
        if total_cache_requests > 0:
            cache_hit_rate = (self.cache_hits / total_cache_requests) * 100
            _log_print(f"\n{'='*60}")
            _log_print(f"ğŸ“Š ç¼“å­˜ç»Ÿè®¡:")
            _log_print(f"{'='*60}")
            _log_print(f"  ç¼“å­˜å‘½ä¸­: {self.cache_hits} æ¬¡")
            _log_print(f"  ç¼“å­˜æœªå‘½ä¸­: {self.cache_misses} æ¬¡")
            _log_print(f"  ç¼“å­˜å‘½ä¸­ç‡: {cache_hit_rate:.1f}%")
            cache_stats = self.cache.get_stats()
            _log_print(f"  ç¼“å­˜æ€»æ¡ç›®: {cache_stats['total']} (æœ‰æ•ˆ: {cache_stats['valid']}, è¿‡æœŸ: {cache_stats['expired']})")
            if cache_hit_rate > 0:
                saved_requests = self.cache_hits
                _log_print(f"  ğŸ’¡ èŠ‚çœäº†çº¦ {saved_requests} æ¬¡APIè¯·æ±‚ï¼")
            _log_print(f"{'='*60}\n")
        
        return self.create_sync_result(True, f"æˆåŠŸåŒæ­¥ {count} æ¡å¹¿å‘Šæ•°æ®ï¼ˆè€—æ—¶ {elapsed_time:.2f}ç§’ï¼‰", count)
