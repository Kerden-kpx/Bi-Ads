"""
Google Ads API æ•°æ®åŒæ­¥æœåŠ¡
ç”¨äºä» Google Ads API è·å–æ•°æ®å¹¶åŒæ­¥åˆ°æ•°æ®åº“
ä¼˜åŒ–ç‰ˆæœ¬ï¼šæ”¯æŒå¹¶å‘å¤„ç†ã€æ‰¹é‡æ“ä½œã€è‡ªåŠ¨é‡è¯•ã€å“åº”ç¼“å­˜
"""
import os
import time
import hashlib
import atexit
from threading import Lock
from typing import List, Tuple, Optional, Dict, Any
from google.ads.googleads.client import GoogleAdsClient
from google.ads.googleads.errors import GoogleAdsException
from sqlalchemy.orm import Session
from sqlalchemy import text
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime, timedelta
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type

from app.services.base_sync_service import BaseSyncService
from app.core.config import settings

_executor_cache: Dict[int, ThreadPoolExecutor] = {}
_executor_lock = Lock()


def _get_thread_pool(requested_workers: int, limit: Optional[int] = None) -> ThreadPoolExecutor:
    """
    è·å–æˆ–åˆ›å»ºæŒ‡å®šå¤§å°çš„çº¿ç¨‹æ± ï¼ˆå¤ç”¨å®ä¾‹ï¼Œé¿å…é¢‘ç¹åˆ›å»ºé”€æ¯ï¼‰
    """
    max_allowed = limit or settings.GOOGLE_ADS_MAX_WORKERS
    worker_count = max(1, min(requested_workers, max_allowed))

    with _executor_lock:
        executor = _executor_cache.get(worker_count)
        if executor is None:
            executor = ThreadPoolExecutor(max_workers=worker_count)
            _executor_cache[worker_count] = executor
    return executor


def _shutdown_thread_pools():
    with _executor_lock:
        for executor in _executor_cache.values():
            executor.shutdown(wait=False)
        _executor_cache.clear()


atexit.register(_shutdown_thread_pools)


class GoogleAdsDataSyncService(BaseSyncService):
    """Google Ads æ•°æ®åŒæ­¥æœåŠ¡"""
    
    # ç±»çº§åˆ«çš„å†…å­˜ç¼“å­˜
    _cache = {}
    _cache_ttl = {}  # ç¼“å­˜è¿‡æœŸæ—¶é—´
    CACHE_DURATION = 300  # ç¼“å­˜5åˆ†é’Ÿ
    
    def __init__(self, db: Session, config_path: str = None):
        """
        åˆå§‹åŒ–æœåŠ¡
        
        Args:
            db: æ•°æ®åº“ä¼šè¯
            config_path: Google Ads é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤ä»é…ç½®è¯»å–ï¼‰
        """
        super().__init__(db, "fact_bi_ads_google_campaign")
        
        # ä»é…ç½®è¯»å–è·¯å¾„ï¼Œæ”¯æŒç›¸å¯¹è·¯å¾„å’Œç»å¯¹è·¯å¾„
        if config_path:
            self.config_path = config_path
        else:
            # ä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®è·¯å¾„
            config_path_from_env = settings.GOOGLE_ADS_CONFIG_PATH
            # å¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„ï¼Œè½¬æ¢ä¸ºç»å¯¹è·¯å¾„ï¼ˆç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•ï¼‰
            if not os.path.isabs(config_path_from_env):
                # è·å–é¡¹ç›®æ ¹ç›®å½•ï¼ˆbackendç›®å½•ï¼‰
                project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
                self.config_path = os.path.join(project_root, config_path_from_env)
            else:
                self.config_path = config_path_from_env
        
        self.client = None
        
    def setup_proxy(self, proxy_url: str = None):
        """è®¾ç½®ä»£ç†ç¯å¢ƒå˜é‡"""
        # ä»é…ç½®è¯»å–ä»£ç†åœ°å€
        if proxy_url is None:
            proxy_url = settings.GOOGLE_ADS_PROXY_URL_EFFECTIVE
        
        if proxy_url:
            os.environ['HTTP_PROXY'] = proxy_url
            os.environ['HTTPS_PROXY'] = proxy_url
            os.environ['http_proxy'] = proxy_url
            os.environ['https_proxy'] = proxy_url
            print(f"ğŸ”§ å·²è®¾ç½®ä»£ç†: {proxy_url}")
        else:
            print("âš ï¸  æœªè®¾ç½®ä»£ç†")
    
    def initialize_client(self):
        """
        åˆå§‹åŒ– Google Ads å®¢æˆ·ç«¯
        ä½¿ç”¨ç®€å•ç›´æ¥çš„åŠ è½½æ–¹å¼ï¼ˆå·²éªŒè¯å¯å·¥ä½œï¼‰
        """
        try:
            # åˆ‡æ¢åˆ°é…ç½®æ–‡ä»¶æ‰€åœ¨ç›®å½•ï¼ˆå…³é”®ï¼ï¼‰
            original_dir = os.getcwd()
            config_dir = os.path.dirname(os.path.abspath(self.config_path))
            config_filename = os.path.basename(self.config_path)
            
            print(f"ğŸ“‚ åˆ‡æ¢åˆ°é…ç½®ç›®å½•: {config_dir}")
            os.chdir(config_dir)
            
            try:
                # ä½¿ç”¨ç®€å•çš„æ–‡ä»¶ååŠ è½½ï¼ˆä¸æˆåŠŸçš„è„šæœ¬ä¸€è‡´ï¼‰
                self.client = GoogleAdsClient.load_from_storage(config_filename)
                print("âœ… Google Ads å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
                return True
            finally:
                # æ¢å¤åŸå§‹å·¥ä½œç›®å½•
                os.chdir(original_dir)
                
        except Exception as e:
            print(f"âŒ åˆå§‹åŒ– Google Ads å®¢æˆ·ç«¯å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def _generate_date_list(self, start_date: str, end_date: str) -> List[str]:
        """ç”Ÿæˆæ—¥æœŸèŒƒå›´å†…çš„æ‰€æœ‰æ—¥æœŸåˆ—è¡¨"""
        start = datetime.strptime(start_date, '%Y-%m-%d')
        end = datetime.strptime(end_date, '%Y-%m-%d')
        date_list = []
        current = start
        while current <= end:
            date_list.append(current.strftime('%Y-%m-%d'))
            current += timedelta(days=1)
        return date_list
    
    def _fetch_single_date_data(
        self,
        customer_id: str,
        date: str
    ) -> Tuple[bool, List[Tuple], str]:
        """
        è·å–å•ä¸ªæ—¥æœŸçš„æ•°æ®ï¼ˆç”¨äºå¹¶å‘å¤„ç†ï¼‰
        
        Args:
            customer_id: Google Ads å®¢æˆ·ID
            date: æ—¥æœŸ
            
        Returns:
            (æˆåŠŸæ ‡å¿—, æ•°æ®åˆ—è¡¨, é”™è¯¯ä¿¡æ¯)
        """
        if not self.client:
            return False, [], "å®¢æˆ·ç«¯æœªåˆå§‹åŒ–"
        
        try:
            ga_service = self.client.get_service("GoogleAdsService")
            
            # SQLæŸ¥è¯¢è¯­å¥ï¼ˆå•æ—¥ï¼‰
            query = f"""
                SELECT campaign.id,
                       campaign.name,
                       metrics.impressions,
                       metrics.conversions,
                       metrics.cost_micros,
                       metrics.clicks,
                       metrics.conversions_value,
                       segments.date
                FROM campaign
                WHERE segments.date = '{date}'
            """
            
            # æ‰§è¡ŒæŸ¥è¯¢
            stream = ga_service.search_stream(customer_id=customer_id, query=query)
            
            ads_data = []
            
            # è§£ææŸ¥è¯¢ç»“æœ
            for batch in stream:
                for row in batch.results:
                    campaign = row.campaign
                    metrics = row.metrics
                    segments = row.segments
                    
                    # è½¬åŒ–æ¬¡æ•°ä¿ç•™ä¸¤ä½å°æ•°
                    conversions = round(metrics.conversions, 2)
                    # è½¬åŒ–ä»·å€¼ä¿ç•™ä¸¤ä½å°æ•°
                    conversions_value = round(metrics.conversions_value, 2)
                    # è´¹ç”¨é™¤ä»¥10çš„å…­æ¬¡æ–¹,ä¿ç•™ä¸¤ä½å°æ•°
                    cost = round(float(metrics.cost_micros) / 1000000, 2)
                    
                    # å°†æ•°æ®å­˜å‚¨åˆ°åˆ—è¡¨ä¸­
                    ads_data.append((
                        campaign.id,
                        campaign.name,
                        metrics.impressions,
                        conversions,
                        cost,
                        metrics.clicks,
                        conversions_value,
                        segments.date
                    ))
            
            return True, ads_data, ""
            
        except Exception as e:
            error_msg = f"è·å– {date} æ•°æ®å¤±è´¥: {str(e)}"
            return False, [], error_msg
    
    def _generate_cache_key(self, customer_id: str, start_date: str, end_date: str, data_type: str = "summary") -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        key_string = f"{customer_id}:{start_date}:{end_date}:{data_type}"
        return hashlib.md5(key_string.encode()).hexdigest()
    
    def _get_from_cache(self, cache_key: str) -> Optional[Tuple[Dict, List]]:
        """ä»ç¼“å­˜è·å–æ•°æ®"""
        if cache_key in self._cache:
            # æ£€æŸ¥ç¼“å­˜æ˜¯å¦è¿‡æœŸ
            if time.time() < self._cache_ttl.get(cache_key, 0):
                print(f"ğŸ¯ ä»ç¼“å­˜è·å–æ•°æ®: {cache_key[:8]}...")
                return self._cache[cache_key]
            else:
                # æ¸…é™¤è¿‡æœŸç¼“å­˜
                del self._cache[cache_key]
                if cache_key in self._cache_ttl:
                    del self._cache_ttl[cache_key]
        return None
    
    def _set_to_cache(self, cache_key: str, data: Tuple[Dict, List]):
        """è®¾ç½®ç¼“å­˜"""
        self._cache[cache_key] = data
        self._cache_ttl[cache_key] = time.time() + self.CACHE_DURATION
        print(f"ğŸ’¾ æ•°æ®å·²ç¼“å­˜: {cache_key[:8]}... (TTL: {self.CACHE_DURATION}ç§’)")
    
    @retry(
        stop=stop_after_attempt(3),  # æœ€å¤šé‡è¯•3æ¬¡
        wait=wait_exponential(multiplier=1, min=2, max=10),  # æŒ‡æ•°é€€é¿ï¼š2s, 4s, 8s
        retry=retry_if_exception_type((ConnectionError, TimeoutError, Exception)),  # é‡è¯•è¿™äº›é”™è¯¯
        reraise=True  # æœ€ç»ˆå¤±è´¥æ—¶æŠ›å‡ºåŸå§‹å¼‚å¸¸
    )
    def _fetch_summary_data(self, customer_id: str, start_date: str, end_date: str) -> Tuple[Dict, List]:
        """è·å–å•ä¸ªæ—¶é—´æ®µçš„æ±‡æ€»å’Œæ¯æ—¥æ•°æ®ï¼ˆçº¿ç¨‹å®‰å…¨ï¼Œæ”¯æŒè‡ªåŠ¨é‡è¯•ï¼Œå¸¦ç¼“å­˜ï¼‰"""
        # æ£€æŸ¥ç¼“å­˜
        cache_key = self._generate_cache_key(customer_id, start_date, end_date, "summary")
        cached_data = self._get_from_cache(cache_key)
        if cached_data:
            return cached_data
        
        # æ¯ä¸ªçº¿ç¨‹è·å–è‡ªå·±çš„æœåŠ¡å®ä¾‹ä»¥ä¿è¯çº¿ç¨‹å®‰å…¨
        ga_service = self.client.get_service("GoogleAdsService")
        
        # æ±‡æ€»æŸ¥è¯¢
        summary_query = f"""
            SELECT 
                metrics.impressions,
                metrics.clicks,
                metrics.conversions,
                metrics.conversions_value,
                metrics.cost_micros,
                metrics.ctr,
                metrics.average_cpc,
                metrics.cost_per_conversion
            FROM customer
            WHERE segments.date BETWEEN '{start_date}' AND '{end_date}'
        """
        
        # æ¯æ—¥æ•°æ®æŸ¥è¯¢
        daily_query = f"""
            SELECT 
                segments.date,
                metrics.impressions,
                metrics.clicks,
                metrics.conversions,
                metrics.conversions_value,
                metrics.cost_micros
            FROM customer
            WHERE segments.date BETWEEN '{start_date}' AND '{end_date}'
            ORDER BY segments.date
        """
        
        summary_response = ga_service.search(customer_id=customer_id, query=summary_query)
        daily_response = ga_service.search(customer_id=customer_id, query=daily_query)
        
        # è§£ææ±‡æ€»æ•°æ®
        summary = {}
        for row in summary_response:
            metrics = row.metrics
            summary = {
                "impressions": metrics.impressions,
                "clicks": metrics.clicks,
                "conversions": metrics.conversions,
                "conversions_value": metrics.conversions_value,
                "cost": float(metrics.cost_micros) / 1000000,
                "ctr": metrics.ctr * 100,
                "average_cpc": float(metrics.average_cpc) / 1000000,
                "cost_per_conversion": float(metrics.cost_per_conversion) / 1000000 if metrics.cost_per_conversion > 0 else 0
            }
        
        # è§£ææ¯æ—¥æ•°æ®
        daily_data = []
        for row in daily_response:
            segments = row.segments
            metrics = row.metrics
            daily_data.append({
                "date": segments.date,
                "impressions": metrics.impressions,
                "clicks": metrics.clicks,
                "conversions": metrics.conversions,
                "conversions_value": metrics.conversions_value,
                "cost": float(metrics.cost_micros) / 1000000
            })
        
        # ç¼“å­˜ç»“æœ
        result = (summary, daily_data)
        self._set_to_cache(cache_key, result)
        
        return result
    
    def fetch_overview_summary(
        self, 
        customer_id: str, 
        start_date: str,
        end_date: str,
        compare_start_date: Optional[str] = None,
        compare_end_date: Optional[str] = None
    ) -> Tuple[bool, Dict[str, Any], str]:
        """
        ä» Google Ads API è·å–æ¦‚è§ˆæ±‡æ€»æ•°æ®ï¼ˆå¹¶å‘æ‰§è¡Œï¼Œæå‡é€Ÿåº¦ï¼‰
        ç”¨äº Top Funnel Overview å’Œ Conversion Value & Cost Overview
        
        Args:
            customer_id: Google Ads å®¢æˆ·ID
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            compare_start_date: å¯¹æ¯”å¼€å§‹æ—¥æœŸï¼ˆå¯é€‰ï¼‰
            compare_end_date: å¯¹æ¯”ç»“æŸæ—¥æœŸï¼ˆå¯é€‰ï¼‰
            
        Returns:
            (æˆåŠŸæ ‡å¿—, æ±‡æ€»æ•°æ®å­—å…¸, é”™è¯¯ä¿¡æ¯)
        """
        if not self.client:
            return False, {}, "å®¢æˆ·ç«¯æœªåˆå§‹åŒ–"
        
        try:
            import time
            start_time = time.time()
            
            # æ£€æŸ¥å®Œæ•´è¯·æ±‚çš„ç¼“å­˜ï¼ˆåŒ…å«å¯¹æ¯”æœŸï¼‰
            full_cache_key = self._generate_cache_key(
                customer_id, 
                f"{start_date}:{end_date}:{compare_start_date}:{compare_end_date}",
                "",
                "overview"
            )
            cached_full_data = self._get_from_cache(full_cache_key)
            if cached_full_data:
                elapsed = time.time() - start_time
                print(f"âš¡ ä»ç¼“å­˜è·å–å®Œæ•´æ¦‚è§ˆæ•°æ®ï¼Œè€—æ—¶: {elapsed:.2f}ç§’")
                return True, cached_full_data[0], ""
            
            # ä½¿ç”¨å¹¶å‘æ‰§è¡Œæå‡é€Ÿåº¦ï¼ˆå—é…ç½®é™åˆ¶çš„çº¿ç¨‹æ± ï¼‰
            
            # åˆå§‹åŒ–æ±‡æ€»æ•°æ®
            summary_data = {
                "impressions": 0,
                "clicks": 0,
                "conversions": 0.0,
                "conversions_value": 0.0,
                "cost": 0.0,
                "ctr": 0.0,
                "average_cpc": 0.0,
                "cost_per_conversion": 0.0,
                "daily_data": [],
                # å¯¹æ¯”æœŸæ•°æ®
                "compare_impressions": 0,
                "compare_clicks": 0,
                "compare_conversions": 0.0,
                "compare_conversions_value": 0.0,
                "compare_cost": 0.0,
                "compare_ctr": 0.0,
                "compare_average_cpc": 0.0,
                "compare_cost_per_conversion": 0.0,
                "compare_daily_data": []
            }
            
            # å¹¶å‘æ‰§è¡ŒæŸ¥è¯¢ï¼ˆçº¿ç¨‹å®‰å…¨ï¼Œå¤ç”¨çº¿ç¨‹æ± ä»¥å‡å°‘å¼€é”€ï¼‰
            executor = _get_thread_pool(4, settings.GOOGLE_ADS_SUMMARY_MAX_WORKERS)
            
            # æäº¤å½“å‰æœŸæ•°æ®è·å–ä»»åŠ¡
            future_current = executor.submit(
                self._fetch_summary_data,
                customer_id,
                start_date,
                end_date
            )
            
            # å¦‚æœæœ‰å¯¹æ¯”æœŸï¼Œæäº¤å¯¹æ¯”æœŸæ•°æ®è·å–ä»»åŠ¡
            future_compare = None
            if compare_start_date and compare_end_date:
                future_compare = executor.submit(
                    self._fetch_summary_data,
                    customer_id,
                    compare_start_date,
                    compare_end_date
                )
            
            # è·å–å½“å‰æœŸæ•°æ®
            current_summary, current_daily = future_current.result()
            summary_data.update(current_summary)
            summary_data["daily_data"] = current_daily
            
            # è·å–å¯¹æ¯”æœŸæ•°æ®
            if future_compare:
                compare_summary, compare_daily = future_compare.result()
                summary_data["compare_impressions"] = compare_summary.get("impressions", 0)
                summary_data["compare_clicks"] = compare_summary.get("clicks", 0)
                summary_data["compare_conversions"] = compare_summary.get("conversions", 0)
                summary_data["compare_conversions_value"] = compare_summary.get("conversions_value", 0)
                summary_data["compare_cost"] = compare_summary.get("cost", 0)
                summary_data["compare_ctr"] = compare_summary.get("ctr", 0)
                summary_data["compare_average_cpc"] = compare_summary.get("average_cpc", 0)
                summary_data["compare_cost_per_conversion"] = compare_summary.get("cost_per_conversion", 0)
                summary_data["compare_daily_data"] = compare_daily
            
            elapsed = time.time() - start_time
            
            print(f"\nğŸ“Š æ¦‚è§ˆæ±‡æ€»æ•°æ® ({start_date} è‡³ {end_date}):")
            print(f"   å±•ç¤ºæ¬¡æ•°: {summary_data['impressions']:,}")
            print(f"   ç‚¹å‡»æ¬¡æ•°: {summary_data['clicks']:,}")
            print(f"   ç‚¹å‡»ç‡: {summary_data['ctr']:.2f}%")
            print(f"   è½¬åŒ–æ¬¡æ•°: {summary_data['conversions']:,}")
            print(f"   è½¬åŒ–ä»·å€¼: ${summary_data['conversions_value']:,.2f}")
            print(f"   æ€»æˆæœ¬: ${summary_data['cost']:,.2f}")
            print(f"   å¹³å‡CPC: ${summary_data['average_cpc']:.2f}")
            print(f"   æ¯æ—¥æ•°æ®ç‚¹: {len(summary_data['daily_data'])} å¤©")
            print(f"   âš¡ APIè¯·æ±‚è€—æ—¶: {elapsed:.2f}ç§’")
            
            if compare_start_date and compare_end_date:
                print(f"\nğŸ“Š å¯¹æ¯”æœŸæ•°æ® ({compare_start_date} è‡³ {compare_end_date}):")
                print(f"   å±•ç¤ºæ¬¡æ•°: {summary_data['compare_impressions']:,}")
                print(f"   ç‚¹å‡»æ¬¡æ•°: {summary_data['compare_clicks']:,}")
                print(f"   å¯¹æ¯”æœŸæ•°æ®ç‚¹: {len(summary_data['compare_daily_data'])} å¤©")
            
            # ç¼“å­˜å®Œæ•´ç»“æœ
            self._set_to_cache(full_cache_key, (summary_data, []))
            
            return True, summary_data, ""
            
        except GoogleAdsException as ex:
            print(f"âŒ Google Ads API é”™è¯¯:")
            error_msg = ""
            for error in ex.failure.errors:
                print(f"   é”™è¯¯ä»£ç : {error.error_code.name}")
                print(f"   é”™è¯¯ä¿¡æ¯: {error.message}")
                error_msg += f"é”™è¯¯ä»£ç : {error.error_code.name}, é”™è¯¯ä¿¡æ¯: {error.message}\n"
            return False, {}, error_msg
            
        except Exception as e:
            error_msg = f"è·å–æ¦‚è§ˆæ±‡æ€»æ•°æ®æ—¶å‡ºé”™: {str(e)}"
            print(f"âŒ {error_msg}")
            return False, {}, error_msg
    
    def fetch_campaigns_data(
        self, 
        customer_id: str, 
        start_date: str,
        end_date: str
    ) -> Tuple[bool, List[Tuple], str]:
        """
        ä» Google Ads API è·å–å¹¿å‘Šç³»åˆ—æ•°æ®ï¼ˆä¸²è¡Œç‰ˆæœ¬ï¼Œä¿ç•™ç”¨äºå…¼å®¹ï¼‰
        
        Args:
            customer_id: Google Ads å®¢æˆ·ID
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            
        Returns:
            (æˆåŠŸæ ‡å¿—, æ•°æ®åˆ—è¡¨, é”™è¯¯ä¿¡æ¯)
        """
        if not self.client:
            return False, [], "å®¢æˆ·ç«¯æœªåˆå§‹åŒ–"
        
        try:
            ga_service = self.client.get_service("GoogleAdsService")
            
            # SQLæŸ¥è¯¢è¯­å¥
            query = f"""
                SELECT campaign.id,              --å¹¿å‘Šç³»åˆ—ID
                       campaign.name,            --å¹¿å‘Šç³»åˆ—åç§°
                       metrics.impressions,      --å±•ç¤ºæ¬¡æ•°
                       metrics.conversions,      --è½¬åŒ–æ¬¡æ•°
                       metrics.cost_micros,      --è´¹ç”¨
                       metrics.clicks,           --ç‚¹å‡»æ¬¡æ•°
                       metrics.conversions_value,--è½¬åŒ–ä»·å€¼ 
                       segments.date             -- æ—¥æœŸ
                FROM campaign
                WHERE segments.date BETWEEN '{start_date}' AND '{end_date}'
            """
            
            # æ‰§è¡ŒæŸ¥è¯¢
            stream = ga_service.search_stream(customer_id=customer_id, query=query)
            
            campaigns_found = 0
            ads_data = []
            
            # è§£ææŸ¥è¯¢ç»“æœ
            for batch in stream:
                for row in batch.results:
                    campaign = row.campaign
                    metrics = row.metrics
                    segments = row.segments
                    campaigns_found += 1
                    
                    # è½¬åŒ–æ¬¡æ•°ä¿ç•™ä¸¤ä½å°æ•°
                    conversions = round(metrics.conversions, 2)
                    # è½¬åŒ–ä»·å€¼ä¿ç•™ä¸¤ä½å°æ•°
                    conversions_value = round(metrics.conversions_value, 2)
                    # è´¹ç”¨é™¤ä»¥10çš„å…­æ¬¡æ–¹,ä¿ç•™ä¸¤ä½å°æ•°
                    cost = round(float(metrics.cost_micros) / 1000000, 2)
                    
                    # å°†æ•°æ®å­˜å‚¨åˆ°åˆ—è¡¨ä¸­
                    ads_data.append((
                        campaign.id,
                        campaign.name,
                        metrics.impressions,
                        conversions,
                        cost,
                        metrics.clicks,
                        conversions_value,
                        segments.date
                    ))
                    
                    print(f"{campaign.id:<12} {campaign.name:<30} {metrics.impressions:<12} {conversions:<20} {metrics.cost_micros:<20.2f} {metrics.clicks:<20} {conversions_value:<20} {segments.date:<20}")
            
            print(f"æ€»å…±æ‰¾åˆ° {campaigns_found} ä¸ªå¹¿å‘Šç³»åˆ—")
            return True, ads_data, ""
            
        except GoogleAdsException as ex:
            print(f"âŒ Google Ads API é”™è¯¯:")
            error_msg = ""
            for error in ex.failure.errors:
                print(f"   é”™è¯¯ä»£ç : {error.error_code.name}")
                print(f"   é”™è¯¯ä¿¡æ¯: {error.message}")
                error_msg += f"é”™è¯¯ä»£ç : {error.error_code.name}, é”™è¯¯ä¿¡æ¯: {error.message}\n"
                if error.location:
                    for field_path_element in error.location.field_path_elements:
                        print(f"   å­—æ®µ: {field_path_element.field_name}")
            return False, [], error_msg
            
        except Exception as e:
            error_msg = f"è·å–å¹¿å‘Šç³»åˆ—æ—¶å‡ºé”™: {str(e)}"
            print(f"âŒ {error_msg}")
            return False, [], error_msg
    
    def fetch_campaigns_data_concurrent(
        self, 
        customer_id: str, 
        start_date: str,
        end_date: str,
        max_workers: int = 5
    ) -> Tuple[bool, List[Tuple], str]:
        """
        ä» Google Ads API å¹¶å‘è·å–å¹¿å‘Šç³»åˆ—æ•°æ®ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼‰
        
        Args:
            customer_id: Google Ads å®¢æˆ·ID
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            max_workers: æœ€å¤§å¹¶å‘çº¿ç¨‹æ•°ï¼ˆGoogle Ads API å»ºè®®è¾ƒå°‘å¹¶å‘ï¼‰
            
        Returns:
            (æˆåŠŸæ ‡å¿—, æ•°æ®åˆ—è¡¨, é”™è¯¯ä¿¡æ¯)
        """
        if not self.client:
            return False, [], "å®¢æˆ·ç«¯æœªåˆå§‹åŒ–"
        
        try:
            # ç”Ÿæˆæ—¥æœŸåˆ—è¡¨
            date_list = self._generate_date_list(start_date, end_date)
            print(f"ğŸ“… å°†å¹¶å‘è·å– {len(date_list)} å¤©çš„æ•°æ®: {start_date} åˆ° {end_date}")
            effective_workers = min(max_workers, settings.GOOGLE_ADS_MAX_WORKERS)
            if effective_workers != max_workers:
                print(f"ğŸš€ è¯·æ±‚ {max_workers} ä¸ªå¹¶å‘çº¿ç¨‹ï¼Œå·²æ ¹æ®é…ç½®é™åˆ¶ä¸º {effective_workers} ä¸ª")
            else:
                print(f"ğŸš€ ä½¿ç”¨ {effective_workers} ä¸ªå¹¶å‘çº¿ç¨‹")
            
            all_ads_data = []
            completed_dates = 0
            total_dates = len(date_list)
            
            # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘è·å–æ•°æ®ï¼ˆå¤ç”¨çº¿ç¨‹æ± ï¼Œå‡å°‘åˆ›å»ºé”€æ¯å¼€é”€ï¼‰
            executor = _get_thread_pool(effective_workers)
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_date = {
                executor.submit(self._fetch_single_date_data, customer_id, date): date
                for date in date_list
            }
            
            # æ”¶é›†ç»“æœ
            for future in as_completed(future_to_date):
                date = future_to_date[future]
                completed_dates += 1
                
                try:
                    success, date_data, error_msg = future.result()
                    if success and date_data:
                        all_ads_data.extend(date_data)
                    elif not success:
                        print(f"   âš ï¸  {date} è·å–å¤±è´¥: {error_msg}")
                    
                    # æ˜¾ç¤ºè¿›åº¦
                    progress = (completed_dates / total_dates) * 100
                    print(f"â³ è¿›åº¦: {completed_dates}/{total_dates} ({progress:.1f}%) - å·²è·å– {len(all_ads_data)} æ¡æ•°æ®")
                except Exception as e:
                    print(f"   âš ï¸  {date} å¤„ç†å¤±è´¥: {e}")
            
            print(f"\nğŸ‰ å¹¶å‘è·å–å®Œæˆï¼æ€»å…±æ‰¾åˆ° {len(all_ads_data)} æ¡å¹¿å‘Šæ•°æ®")
            return True, all_ads_data, ""
            
        except Exception as e:
            error_msg = f"å¹¶å‘è·å–æ•°æ®å¤±è´¥: {str(e)}"
            print(f"âŒ {error_msg}")
            return False, [], error_msg
    
    def sync_to_database(
        self, 
        data_list: List[Tuple],
        start_date: str,
        end_date: str,
        clear_existing: bool = True
    ) -> Tuple[bool, str]:
        """
        åŒæ­¥æ•°æ®åˆ°æ•°æ®åº“
        
        Args:
            data_list: è¦æ’å…¥çš„æ•°æ®åˆ—è¡¨
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            clear_existing: æ˜¯å¦æ¸…ç©ºæ—¥æœŸèŒƒå›´å†…çš„ç°æœ‰æ•°æ®
            
        Returns:
            (æˆåŠŸæ ‡å¿—, æ¶ˆæ¯)
        """
        if not data_list:
            return False, "æ²¡æœ‰æ•°æ®éœ€è¦åŒæ­¥"
        
        try:
            # æ¸…ç©ºæŒ‡å®šæ—¥æœŸèŒƒå›´å†…çš„æ•°æ®ï¼ˆå¦‚æœéœ€è¦ï¼‰
            if clear_existing:
                self.delete_data_in_range(start_date, end_date)
            
            # å‡†å¤‡SQLè¯­å¥
            insert_query = text("""
                INSERT INTO fact_bi_ads_google_campaign (
                    campaign_id, campaign, impression, 
                    conversions, cost, clicks, conversion_value, createtime
                )
                VALUES (
                    :campaign_id, :campaign, :impression,
                    :conversions, :cost, :clicks, :conversion_value, :createtime
                )
            """)
            
            # è½¬æ¢æ•°æ®ä¸ºå­—å…¸æ ¼å¼
            data_dicts = [
                {
                    "campaign_id": data[0],
                    "campaign": data[1],
                    "impression": data[2],
                    "conversions": data[3],
                    "cost": data[4],
                    "clicks": data[5],
                    "conversion_value": data[6],
                    "createtime": data[7]
                }
                for data in data_list
            ]
            
            # æ‰¹é‡æ’å…¥
            count = self.batch_insert(insert_query, data_dicts)
            message = f"æˆåŠŸæ’å…¥ {count} æ¡æ•°æ®"
            return True, message
            
        except Exception as e:
            self.db.rollback()
            error_msg = f"æ•°æ®åº“é”™è¯¯: {str(e)}"
            print(error_msg)
            return False, error_msg
    
    def sync_campaigns(
        self,
        customer_id: str,
        start_date: str,
        end_date: str,
        proxy_url: Optional[str] = None,
        clear_existing: bool = True,
        use_concurrent: bool = True,
        max_workers: int = 10  # æå‡å¹¶å‘æ•°ï¼š5 -> 10
    ) -> Dict[str, Any]:
        """
        å®Œæ•´çš„åŒæ­¥æµç¨‹ï¼šè·å–æ•°æ®å¹¶åŒæ­¥åˆ°æ•°æ®åº“ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼‰
        
        Args:
            customer_id: Google Ads å®¢æˆ·ID
            start_date: å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)
            end_date: ç»“æŸæ—¥æœŸ (YYYY-MM-DD)
            proxy_url: ä»£ç†URLï¼ˆå¯é€‰ï¼‰
            clear_existing: æ˜¯å¦æ¸…ç©ºç°æœ‰æ•°æ®
            use_concurrent: æ˜¯å¦ä½¿ç”¨å¹¶å‘æ¨¡å¼ï¼ˆé»˜è®¤Trueï¼Œæ€§èƒ½æ›´å¥½ï¼‰
            max_workers: å¹¶å‘çº¿ç¨‹æ•°ï¼ˆé»˜è®¤5ï¼ŒGoogle Ads APIå»ºè®®è¾ƒå°‘å¹¶å‘ï¼‰
            
        Returns:
            åŒ…å«æ‰§è¡Œç»“æœçš„å­—å…¸
        """
        start_time = time.time()
        
        try:
            print(f"\n{'='*60}")
            print(f"ğŸš€ å¼€å§‹åŒæ­¥ Google Ads æ•°æ®ï¼ˆ{'å¹¶å‘' if use_concurrent else 'ä¸²è¡Œ'}æ¨¡å¼ï¼‰")
            print(f"ğŸ“… æ—¥æœŸèŒƒå›´: {start_date} åˆ° {end_date}")
            print(f"{'='*60}\n")
            
            # è®¾ç½®ä»£ç†ï¼ˆå¦‚æœæä¾›ï¼‰
            if proxy_url:
                self.setup_proxy(proxy_url)
            
            # åˆå§‹åŒ–å®¢æˆ·ç«¯
            if not self.initialize_client():
                return self.create_sync_result(False, "åˆå§‹åŒ– Google Ads å®¢æˆ·ç«¯å¤±è´¥", 0, ["åˆå§‹åŒ–å¤±è´¥"])
            
            # è·å–æ•°æ®ï¼ˆé€‰æ‹©å¹¶å‘æˆ–ä¸²è¡Œæ¨¡å¼ï¼‰
            print("\nğŸ“¡ ä» Google Ads API è·å–æ•°æ®...")
            if use_concurrent:
                success, data_list, error_msg = self.fetch_campaigns_data_concurrent(
                    customer_id, start_date, end_date, max_workers
                )
            else:
                success, data_list, error_msg = self.fetch_campaigns_data(
                    customer_id, start_date, end_date
                )
            
            if not success:
                return self.create_sync_result(False, error_msg, 0, [error_msg])
            
            print(f"âœ… æˆåŠŸè·å– {len(data_list)} æ¡å¹¿å‘Šæ•°æ®")
            
            # åŒæ­¥åˆ°æ•°æ®åº“
            print("\nğŸ’¾ å†™å…¥æ•°æ®åº“...")
            success, message = self.sync_to_database(data_list, start_date, end_date, clear_existing)
            if not success:
                return self.create_sync_result(False, message, 0, [message])
            
            elapsed_time = time.time() - start_time
            
            print(f"\n{'='*60}")
            print(f"âœ… Google Ads æ•°æ®åŒæ­¥å®Œæˆï¼")
            print(f"ğŸ“Š å…±åŒæ­¥ {len(data_list)} æ¡è®°å½•")
            print(f"â±ï¸  æ€»è€—æ—¶: {elapsed_time:.2f} ç§’")
            print(f"âš¡ å¹³å‡é€Ÿåº¦: {len(data_list)/elapsed_time:.2f} æ¡/ç§’")
            print(f"{'='*60}\n")
            
            # æˆåŠŸ
            return self.create_sync_result(True, f"{message}ï¼ˆè€—æ—¶ {elapsed_time:.2f}ç§’ï¼‰", len(data_list))
            
        except Exception as e:
            error_msg = f"åŒæ­¥è¿‡ç¨‹å‡ºé”™: {str(e)}"
            return self.create_sync_result(False, error_msg, 0, [error_msg])
